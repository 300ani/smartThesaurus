{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantically related words using pre-trained embeddings\n",
    "\n",
    "In this notebook, pre-trained word embeddings using word2vec on google news corpus or GloVe on Twitter data is utilized to arrive at synsets (synomyms sets) that are words with similar meanings.\n",
    "\n",
    "**Gensim word2vec APIs**: https://radimrehurek.com/gensim/models/word2vec.html\n",
    "\n",
    "**Pre-trained word2vec model on google news**: https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing\n",
    "\n",
    "**Pre-trained GloVe model on Twitter 2B tweets**: https://nlp.stanford.edu/projects/glove/\n",
    "\n",
    "The above models are in the form of binary/text files that can be loaded into the environment at runtime.\n",
    "\n",
    "**Evaluation**\n",
    "\n",
    "The evaluation is done using SimLex-999 dataset. This is particularly challenging due to its differentiation between semantic similarity and semantic relatedness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim                     # implements word2vec model infrastructure and provides interfacing APIs \n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['word2vec']                                # list of models to eval: 'word2vec' and 'glove'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded word2vec model.\n"
     ]
    }
   ],
   "source": [
    "if 'word2vec' in models:\n",
    "    # load pre-trained word2vec model\n",
    "    word2vec_vectors = '../pretrained/GoogleNews-vectors-negative300.bin'\n",
    "    w2v = gensim.models.KeyedVectors.load_word2vec_format(word2vec_vectors, binary=True)\n",
    "    print(\"Loaded word2vec model.\")\n",
    "\n",
    "if 'glove' in models:\n",
    "    # load pre-trained GloVe model\n",
    "    glove_vectors = '../pretrained/glove.twitter.27B.200d.txt'\n",
    "    tmp_file = get_tmpfile(\"test_word2vec.txt\")\n",
    "    \n",
    "    glove2word2vec(glove_input_file=glove_vectors, word2vec_output_file=tmp_file)\n",
    "    glove = gensim.models.KeyedVectors.load_word2vec_format(tmp_file)\n",
    "    print(\"Loaded GloVe model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec cosine similarity of ['coffee', 'cup']: 0.3560178279876709\n",
      "word2vec cosine similarity of ['coffee', 'tea']: 0.5635291934013367\n"
     ]
    }
   ],
   "source": [
    "# similarity \n",
    "pair1 = ['coffee','cup']\n",
    "pair2 = ['coffee','tea']\n",
    "\n",
    "if 'word2vec' in models:\n",
    "    cos_dist1_w = w2v.similarity(pair1[0], pair1[1])\n",
    "    cos_dist2_w = w2v.similarity(pair2[0], pair2[1])\n",
    "    print('word2vec cosine similarity of {}: {}'.format(pair1, cos_dist1_w) )\n",
    "    print('word2vec cosine similarity of {}: {}'.format(pair2, cos_dist2_w) )\n",
    "\n",
    "if 'glove' in models:\n",
    "    cos_dist1_g = glove.similarity(pair1[0], pair1[1])\n",
    "    cos_dist2_g = glove.similarity(pair2[0], pair2[1])\n",
    "    print('\\nGloVe cosine similarity of {}: {}'.format(pair1, cos_dist1_g) )\n",
    "    print('GloVe cosine similarity of {}: {}'.format(pair2, cos_dist2_g) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem above is that similarity doesn't always translate to synonyms - the target word 'minor' is closer to 'major' than to 'small'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec Vector embedding dimension:  (300,)\n",
      "\n",
      "Printing a subset of the whole vector for the word 'coffee':\n",
      "[-0.13671875 -0.37304688  0.6171875   0.10839844  0.02722168  0.10009766\n",
      " -0.15136719 -0.01660156  0.38085938  0.06542969 -0.13183594  0.25390625\n",
      "  0.09082031  0.02868652  0.25390625 -0.20507812  0.1640625   0.22070312\n",
      " -0.17480469]\n"
     ]
    }
   ],
   "source": [
    "# vector representation of the word\n",
    "\n",
    "if 'word2vec' in models:\n",
    "    vec_pair1_0_w = w2v.get_vector(pair1[0])\n",
    "    print(\"word2vec Vector embedding dimension: \",vec_pair1_0_w.shape)\n",
    "    print(\"\\nPrinting a subset of the whole vector for the word '{}':\".format(pair1[0]))\n",
    "    print(vec_pair1_0_w[1:20])\n",
    "\n",
    "if 'glove' in models:\n",
    "    vec_pair1_0_g = glove.get_vector(pair1[0])\n",
    "    print(\"\\nGloVe vector embedding dimension: \",vec_pair1_0_g.shape)\n",
    "    print(\"\\nPrinting a subset of the whole vector for the word '{}':\".format(pair1[0]))\n",
    "    print(vec_pair1_0_g[1:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar 15 words (by word) for 'coffee' by word2vec model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('coffees', 0.721267819404602),\n",
       " ('gourmet_coffee', 0.7057087421417236),\n",
       " ('Coffee', 0.6900455355644226),\n",
       " ('o_joe', 0.6891065835952759),\n",
       " ('Starbucks_coffee', 0.6874972581863403),\n",
       " ('coffee_beans', 0.6749703884124756),\n",
       " ('latté', 0.664122462272644),\n",
       " ('cappuccino', 0.6625496745109558),\n",
       " ('brewed_coffee', 0.6621608734130859),\n",
       " ('espresso', 0.6616826057434082),\n",
       " ('java', 0.6504806876182556),\n",
       " ('iced_coffee', 0.6272041201591492),\n",
       " ('freshly_brewed_coffee', 0.6258745193481445),\n",
       " ('coffe', 0.6254313588142395),\n",
       " ('decaf', 0.619594931602478)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# most similar words - by word\n",
    "n_similar = 15\n",
    "thisWord = 'coffee'\n",
    "\n",
    "if 'word2vec' in models:\n",
    "    print(\"Most similar {} words (by word) for '{}' by word2vec model:\".format(n_similar, thisWord))\n",
    "    display(w2v.similar_by_word(thisWord, n_similar))\n",
    "\n",
    "if 'glove' in models:\n",
    "    print(\"\\nMost similar {} words (by word) for '{}' by GloVe model:\".format(n_similar, thisWord))\n",
    "    display(glove.similar_by_word(thisWord, n_similar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the list of similar words returned by the model is different between the word2vec and GloVe models.\n",
    "\n",
    "This is expected as these two pre-trained models have different source corpus.\n",
    "This variety can be utilized to capture more 'potential' candidates, but at the same time, it also burdens the next step to screen out the less relevant ones. \n",
    "\n",
    "Maybe we could utilize the **APSyn/APSynP** for a decisive similarity metric. Another approach would be to rule out outliers using the outlier detection techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar 15 words (by vector) for 'coffee' by word2vec model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('coffees', 0.721267819404602),\n",
       " ('gourmet_coffee', 0.7057087421417236),\n",
       " ('Coffee', 0.6900455355644226),\n",
       " ('o_joe', 0.6891065835952759),\n",
       " ('Starbucks_coffee', 0.6874972581863403),\n",
       " ('coffee_beans', 0.6749703884124756),\n",
       " ('latté', 0.664122462272644),\n",
       " ('cappuccino', 0.6625496745109558),\n",
       " ('brewed_coffee', 0.6621608734130859),\n",
       " ('espresso', 0.6616826057434082),\n",
       " ('java', 0.6504806876182556),\n",
       " ('iced_coffee', 0.6272041201591492),\n",
       " ('freshly_brewed_coffee', 0.6258745193481445),\n",
       " ('coffe', 0.6254313588142395),\n",
       " ('decaf', 0.619594931602478)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# most similar words - by vector\n",
    "\n",
    "if 'word2vec' in models:\n",
    "    print(\"Most similar {} words (by vector) for '{}' by word2vec model:\".format(n_similar, thisWord))\n",
    "    display(w2v.similar_by_vector(thisWord, n_similar))\n",
    "\n",
    "if 'glove' in models:\n",
    "    print(\"\\nMost similar {} words (by vector) for '{}' by GloVe model:\".format(n_similar, thisWord))\n",
    "    display(glove.similar_by_vector(thisWord, n_similar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One analysis to be done is to evaluate similar words returned *by word* contrasted with *by vector* metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>POS</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>conc(w1)</th>\n",
       "      <th>conc(w2)</th>\n",
       "      <th>concQ</th>\n",
       "      <th>Assoc(USF)</th>\n",
       "      <th>SimAssoc333</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old</td>\n",
       "      <td>new</td>\n",
       "      <td>A</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smart</td>\n",
       "      <td>intelligent</td>\n",
       "      <td>A</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1</td>\n",
       "      <td>7.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>difficult</td>\n",
       "      <td>A</td>\n",
       "      <td>8.77</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2</td>\n",
       "      <td>5.94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>cheerful</td>\n",
       "      <td>A</td>\n",
       "      <td>9.55</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1</td>\n",
       "      <td>5.85</td>\n",
       "      <td>1</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>easy</td>\n",
       "      <td>A</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  Assoc(USF)  \\\n",
       "0    old          new   A       1.58      2.72      2.81      2        7.25   \n",
       "1  smart  intelligent   A       9.20      1.75      2.46      1        7.11   \n",
       "2   hard    difficult   A       8.77      3.76      2.21      2        5.94   \n",
       "3  happy     cheerful   A       9.55      2.56      2.34      1        5.85   \n",
       "4   hard         easy   A       0.95      3.76      2.07      2        5.82   \n",
       "\n",
       "   SimAssoc333  SD(SimLex)  \n",
       "0            1        0.41  \n",
       "1            1        0.67  \n",
       "2            1        1.19  \n",
       "3            1        2.18  \n",
       "4            1        0.93  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load evaluation datsets\n",
    "path_evalset1 = '..\\\\datasets\\\\SimLex-999\\\\SimLex-999.txt'\n",
    "evalset1 = pd.read_csv(path_evalset1, sep='\\t')\n",
    "evalset1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above structure for SimLex-999 as evaluation dataset1, we'll be using the word pairs (columns `word1` and `word2`) as well as the `SimLex999` column for score on scale 1-10. Additionally, the `SD(SimLex)` column for standard deviation indicative of agreement between the human annotators for the given word pair, could be used for further investigation and possible waiving, in case discrepancy of the output from the model(s) to be evaluated.\n",
    "\n",
    "**Spearman correlation**\n",
    "\n",
    "Taken from [scipy.stats.spearman()](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.spearmanr.html)\n",
    "\n",
    "The Spearman correlation is a nonparametric measure of the monotonicity of the relationship between two datasets. Unlike the Pearson correlation, the Spearman correlation does not assume that both datasets are normally distributed. Like other correlation coefficients, this one varies between -1 and +1 with 0 implying no correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling cosine score\n",
    "# This scaling might need a non linear function, but for now, a simple linear scaling is being used\n",
    "\n",
    "def scale_cosine(score, scale=10.0):\n",
    "    return scale*score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "      <th>w2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old</td>\n",
       "      <td>new</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.41</td>\n",
       "      <td>2.227803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smart</td>\n",
       "      <td>intelligent</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.67</td>\n",
       "      <td>6.495278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>difficult</td>\n",
       "      <td>8.77</td>\n",
       "      <td>1.19</td>\n",
       "      <td>6.025748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>cheerful</td>\n",
       "      <td>9.55</td>\n",
       "      <td>2.18</td>\n",
       "      <td>3.837738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>easy</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.93</td>\n",
       "      <td>4.709633</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word1        word2  SimLex999  SD(SimLex)       w2v\n",
       "0    old          new       1.58        0.41  2.227803\n",
       "1  smart  intelligent       9.20        0.67  6.495278\n",
       "2   hard    difficult       8.77        1.19  6.025748\n",
       "3  happy     cheerful       9.55        2.18  3.837738\n",
       "4   hard         easy       0.95        0.93  4.709633"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for word2vec model: 0.4420 \n"
     ]
    }
   ],
   "source": [
    "# Evaluating the models scoring on eval datasets\n",
    "\n",
    "models_score = evalset1.filter(items=['word1', 'word2', 'SimLex999', 'SD(SimLex)'])\n",
    "models_score['w2v'] = models_score.apply(lambda row: scale_cosine(\n",
    "    w2v.similarity(row['word1'], row['word2'])), axis=1 )\n",
    "display(models_score.head())\n",
    "w2v_spearman = scipy.stats.spearmanr(models_score['SimLex999'], models_score['w2v'])\n",
    "print('Spearman correlation for word2vec model: {:6.4f} '.format(w2v_spearman[0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps:\n",
    "- Calculate Spearman score for GloVe.\n",
    "- Try other forms of embeddings that can improve upon word2vec e.g. \n",
    "    + GloVe\n",
    "    - fastText \n",
    "- Inspect the performace across less frequent words (fastText should perform better in this scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other resources\n",
    "- http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/\n",
    "- https://www.quora.com/Where-can-I-find-some-pre-trained-word-vectors-for-natural-language-processing-understanding\n",
    "- https://textminingonline.com/getting-started-with-word2vec-and-glove-in-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
