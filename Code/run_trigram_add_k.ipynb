{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, json, time, unittest\n",
    "import itertools, collections\n",
    "from importlib import reload\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "import nltk\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from nltk import word_tokenize\n",
    "import time\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "marshall reported from seattle ; jimenez reported from san jose , costa rica ; associated press writers yuri kageyama and mari yamaguchi in tokyo , jeremiah marquez in hong kong , ray lilley in wellin\n",
      "['Marshall', 'reported', 'from', 'Seattle', ';', 'Jimenez', 'reported', 'from', 'San', 'Jose', ',', 'Costa', 'Rica', ';', 'Associated', 'Press', 'writers', 'Yuri', 'Kageyama', 'and', 'Mari', 'Yamaguchi', 'in', 'Tokyo', ',', 'Jeremiah', 'Marquez', 'in', 'Hong', 'Kong', ',', 'Ray', 'Lilley', 'in', 'Wellin']\n"
     ]
    }
   ],
   "source": [
    "os.chdir('../../datasets/1-billion-word-LM_corpus')\n",
    "filenames = []\n",
    "for filename in os.listdir(os.getcwd()):\n",
    "    filenames.append(filename)\n",
    "file1 = open(filename).read()\n",
    "print(file1[:200].lower())\n",
    "\n",
    "print(word_tokenize(file1[:200]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create context totals/counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ngram(corpus_as_string):\n",
    "    counts = defaultdict(lambda: defaultdict(lambda: 0.0))\n",
    "    context_totals = dict()\n",
    "    corpus_tokenized = word_tokenize(corpus_as_string.lower())\n",
    "    \n",
    "    w_1, w_2 = None, None\n",
    "    wordset = set()\n",
    "    for word in corpus_tokenized:\n",
    "        wordset.add(word)\n",
    "        if w_1 is not None and w_2 is not None:\n",
    "            counts[(w_2,w_1)][word] += 1\n",
    "            # Update context\n",
    "        w_2 = w_1\n",
    "        w_1 = word\n",
    "    for key, value in counts.items():\n",
    "        context_totals[key] = sum(value.values())\n",
    "    return context_totals, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_totals, counts = train_ngram(file1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3548.0\n",
      "11.0\n"
     ]
    }
   ],
   "source": [
    "print(context_totals[('is', 'the')])\n",
    "print(counts[('is', 'the')].get('capital'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get synonyms from sample sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/nathanielschub/Desktop/MIDS/W266/smartThesaurus/Code\n"
     ]
    }
   ],
   "source": [
    "#os.chdir('/smartThesaurus')\n",
    "os.chdir('Code')\n",
    "!pwd\n",
    "sent_1= pd.read_csv('./sentence_generator/output.txt', sep = ',', names = ['pair', 'word', 'sentence'])\n",
    "sent_2= pd.read_csv('./sentence_generator/output_2.txt', sep = ',', names = ['pair', 'word', 'sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = sen.index(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_1 = sent_1.word\n",
    "words_2 = sent_2.word\n",
    "sents_1= sent_1.sentence\n",
    "sents_2 = sent_2.sentence\n",
    "\n",
    "contexts_list_1 = []\n",
    "contexts_list_2 = []\n",
    "\n",
    "for i in range(len(words_1)):\n",
    "    word= words_1[i]\n",
    "    sen = sents_1[i].split()\n",
    "    word_index = sen.index(word)\n",
    "    if word_index > 1:\n",
    "        context = (sen[word_index-2], sen[word_index-1])\n",
    "    elif word_index == 1:\n",
    "        context = (\"_\", sen[word_index-1])\n",
    "    else:\n",
    "        context = (\"_\", \"_\")\n",
    "    contexts_list_1.append(context)\n",
    "    \n",
    "for i in range(len(words_1)):\n",
    "    word= words_2[i]\n",
    "    sen = sents_2[i].split()\n",
    "    word_index = sen.index(word)\n",
    "    if word_index > 1:\n",
    "        context = (sen[word_index-2], sen[word_index-1])\n",
    "    elif word_index == 1:\n",
    "        context = (\".\", sen[word_index-1])\n",
    "    else:\n",
    "        context = (\"_\", \".\")\n",
    "    contexts_list_2.append(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(target_word, context_tuple, k, corpus_as_string):\n",
    "    V = len(np.unique(corpus_as_string.lower().split()[:100]))\n",
    "    x = target_word\n",
    "    context = context_tuple\n",
    "    C_abc = 0.0\n",
    "    if counts.get(context, 0.0) == 0.0:\n",
    "        C_abc = 0.0\n",
    "    else:\n",
    "        C_abc = counts.get(context, 0.0).get(x, 0.0)\n",
    "                \n",
    "    C_ab = context_totals.get(context, 0.0)\n",
    "        \n",
    "    return (C_abc +k)/(C_ab +(k*V))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.4390640258789062\n",
      "100 15.640044927597046\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-348-60f4913f43c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msents_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mscores_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontexts_list_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mscores_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontexts_list_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-125-551182271ea3>\u001b[0m in \u001b[0;36meval\u001b[0;34m(target_word, context_tuple, k, corpus_as_string)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_word\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext_tuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_as_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus_as_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_tuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mC_abc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores_1_1 = []\n",
    "scores_1_2 = []\n",
    "scores_2_1 = []\n",
    "scores_2_2 = []\n",
    "start = time.time()\n",
    "for i in range(len(sents_1)):\n",
    "    if i%10==0:\n",
    "        scores_1_1.append((words_1[i],eval(words_1[i], contexts_list_1[i],1, file1)))\n",
    "        scores_1_2.append((words_1[i],eval(words_2[i], contexts_list_2[i],1, file1)))\n",
    "        scores_2_1.append((words_2[i],eval(words_2[i], contexts_list_1[i],1, file1)))\n",
    "        scores_2_2.append((words_2[i],eval(words_2[i], contexts_list_2[i],1, file1)))\n",
    "\n",
    "        if i%100==0:\n",
    "            print(i,time.time()-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run similarites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_means_1_1 = []\n",
    "running_mean_1_1=[]\n",
    "for i in range(len(scores_1_1)):\n",
    "    if (i+1)%10!=0:        \n",
    "        running_mean_1_1.append(scores_1_1[i][1])\n",
    "    else:\n",
    "        running_mean_1_1.append(scores_1_1[i][1])\n",
    "        word_means_1_1.append((scores_1_1[i][0],np.mean(running_mean_1_1)))\n",
    "        running_mean_1_1=[]\n",
    "        \n",
    "word_means_1_2 =[]\n",
    "running_mean_1_2=[]\n",
    "for i in range(len(scores_1_1)):\n",
    "    if (i+1)%10!=0:        \n",
    "        running_mean_1_2.append(scores_1_2[i][1])\n",
    "    else:\n",
    "        running_mean_1_2.append(scores_1_2[i][1])\n",
    "        word_means_1_2.append((scores_1_2[i][0],np.mean(running_mean_1_2)))\n",
    "        running_mean_1_2=[]\n",
    " \n",
    "word_means_2_1 =[]\n",
    "running_mean_2_1=[]\n",
    "for i in range(len(scores_1_1)):\n",
    "    if (i+1)%10!=0:        \n",
    "        running_mean_2_1.append(scores_2_1[i][1])\n",
    "    else:\n",
    "        running_mean_2_1.append(scores_2_1[i][1])\n",
    "        word_means_2_1.append((scores_2_1[i][0],np.mean(running_mean_2_1)))\n",
    "        running_mean_2_1=[]\n",
    "        \n",
    "word_means_2_2 =[]\n",
    "running_mean_2_2=[]\n",
    "for i in range(len(scores_1_1)):\n",
    "    if (i+1)%10!=0:\n",
    "        running_mean_2_2.append(scores_2_2[i][1])\n",
    "    else:\n",
    "        running_mean_2_2.append(scores_2_2[i][1])\n",
    "        word_means_2_2.append((scores_2_2[i][0],np.mean(running_mean_2_2)))\n",
    "        running_mean_2_2=[]\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('childish', 'foolish')        : 1.0000\n",
      "('child', 'boy')               : 0.9990\n",
      "('child', 'adult')             : 0.9995\n",
      "('author', 'creator')          : 0.9988\n"
     ]
    }
   ],
   "source": [
    "comparison_a=[]\n",
    "comparison_b=[]\n",
    "\n",
    "for i in range(len(word_means_1_1)):\n",
    "    comparison_a.append(((word_means_1_1[i][0], word_means_2_2[i][0]), abs(abs(word_means_1_1[i][1])-abs(word_means_2_1[i][1]))))\n",
    "    comparison_b.append(((word_means_1_1[i][0], word_means_2_2[i][0]), abs(abs(word_means_2_2[i][1])-abs(word_means_1_2[i][1]))))\n",
    "\n",
    "distances={}\n",
    "dist =[]\n",
    "for i in range(len(comparison_a)):\n",
    "#larger must be better for distances\n",
    "    distance= (comparison_a[i][1]+comparison_b[i][1])/2\n",
    "\n",
    "    distances[comparison_a[i][0]] = 1- distance\n",
    "    dist.append(1-distance)\n",
    "for i, wpair in zip(range(0,4),distances):\n",
    "    print(\"{:30s} : {:6.4f}\".format(str(wpair), distances[wpair]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval with Simlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SimLex eval set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>POS</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>conc(w1)</th>\n",
       "      <th>conc(w2)</th>\n",
       "      <th>concQ</th>\n",
       "      <th>Assoc(USF)</th>\n",
       "      <th>SimAssoc333</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old</td>\n",
       "      <td>new</td>\n",
       "      <td>A</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smart</td>\n",
       "      <td>intelligent</td>\n",
       "      <td>A</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1</td>\n",
       "      <td>7.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>difficult</td>\n",
       "      <td>A</td>\n",
       "      <td>8.77</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2</td>\n",
       "      <td>5.94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>cheerful</td>\n",
       "      <td>A</td>\n",
       "      <td>9.55</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1</td>\n",
       "      <td>5.85</td>\n",
       "      <td>1</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>easy</td>\n",
       "      <td>A</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  Assoc(USF)  \\\n",
       "0    old          new   A       1.58      2.72      2.81      2        7.25   \n",
       "1  smart  intelligent   A       9.20      1.75      2.46      1        7.11   \n",
       "2   hard    difficult   A       8.77      3.76      2.21      2        5.94   \n",
       "3  happy     cheerful   A       9.55      2.56      2.34      1        5.85   \n",
       "4   hard         easy   A       0.95      3.76      2.07      2        5.82   \n",
       "\n",
       "   SimAssoc333  SD(SimLex)  \n",
       "0            1        0.41  \n",
       "1            1        0.67  \n",
       "2            1        1.19  \n",
       "3            1        2.18  \n",
       "4            1        0.93  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load evaluation datsets\n",
    "import os\n",
    "#os.chdir('../datasets/SimLex-999')\n",
    "\n",
    "path_evalsetSlex = 'SimLex-999.txt'\n",
    "# path_evalsetWsim = '..\\\\datasets\\\\WordSim-353\\\\combined.csv'\n",
    "# path_evalsetMens = '..\\\\datasets\\\\MEN\\\\MEN_dataset_natural_form_full'\n",
    "\n",
    "evalsetSlex = pd.read_csv(path_evalsetSlex, sep='\\t')\n",
    "# evalsetWsim = pd.read_csv(path_evalsetWsim, sep=',')\n",
    "# evalsetMens = pd.read_csv(path_evalsetMens, sep=' ', header=None)\n",
    "# evalsetMens.columns = ['word1', 'word2', 'MEN_score']\n",
    "\n",
    "print(\"\\nSimLex eval set:\")\n",
    "display(evalsetSlex.head())\n",
    "# print(\"\\nWordSim eval set:\")\n",
    "# display(evalsetWsim.head())\n",
    "# print(\"\\nMEN eval set:\")\n",
    "# display(evalsetMens.head())\n",
    "\n",
    "evalset_name_list = ['SimLex-999'] #, 'WordSim-353', 'MEN (3000)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SimLex-999 eval dataset sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>POS</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>conc(w1)</th>\n",
       "      <th>conc(w2)</th>\n",
       "      <th>concQ</th>\n",
       "      <th>Assoc(USF)</th>\n",
       "      <th>SimAssoc333</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old</td>\n",
       "      <td>new</td>\n",
       "      <td>A</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smart</td>\n",
       "      <td>intelligent</td>\n",
       "      <td>A</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1</td>\n",
       "      <td>7.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>difficult</td>\n",
       "      <td>A</td>\n",
       "      <td>8.77</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2</td>\n",
       "      <td>5.94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>cheerful</td>\n",
       "      <td>A</td>\n",
       "      <td>9.55</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1</td>\n",
       "      <td>5.85</td>\n",
       "      <td>1</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>easy</td>\n",
       "      <td>A</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  Assoc(USF)  \\\n",
       "0    old          new   A       1.58      2.72      2.81      2        7.25   \n",
       "1  smart  intelligent   A       9.20      1.75      2.46      1        7.11   \n",
       "2   hard    difficult   A       8.77      3.76      2.21      2        5.94   \n",
       "3  happy     cheerful   A       9.55      2.56      2.34      1        5.85   \n",
       "4   hard         easy   A       0.95      3.76      2.07      2        5.82   \n",
       "\n",
       "   SimAssoc333  SD(SimLex)  \n",
       "0            1        0.41  \n",
       "1            1        0.67  \n",
       "2            1        1.19  \n",
       "3            1        2.18  \n",
       "4            1        0.93  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "\n",
      "Top and bottom rows of ranked SimLex eval dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "      <th>rank_simlex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vanish</td>\n",
       "      <td>disappear</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quick</td>\n",
       "      <td>rapid</td>\n",
       "      <td>9.70</td>\n",
       "      <td>1.14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>creator</td>\n",
       "      <td>maker</td>\n",
       "      <td>9.62</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stupid</td>\n",
       "      <td>dumb</td>\n",
       "      <td>9.58</td>\n",
       "      <td>1.48</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insane</td>\n",
       "      <td>crazy</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.92</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>gun</td>\n",
       "      <td>fur</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.80</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>chapter</td>\n",
       "      <td>tail</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.57</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>dirty</td>\n",
       "      <td>narrow</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.89</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>new</td>\n",
       "      <td>ancient</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.46</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>shrink</td>\n",
       "      <td>grow</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.20</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word1      word2  SimLex999  SD(SimLex)  rank_simlex\n",
       "0     vanish  disappear       9.80        0.46            1\n",
       "1      quick      rapid       9.70        1.14            2\n",
       "2    creator      maker       9.62        1.40            3\n",
       "3     stupid       dumb       9.58        1.48            4\n",
       "4     insane      crazy       9.57        0.92            5\n",
       "994      gun        fur       0.30        1.80          995\n",
       "995  chapter       tail       0.30        1.57          996\n",
       "996    dirty     narrow       0.30        0.89          997\n",
       "997      new    ancient       0.23        0.46          998\n",
       "998   shrink       grow       0.23        1.20          999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ranking the scores\n",
    "\n",
    "Slex_sorted = evalsetSlex.copy()\n",
    "print(\"\\nSimLex-999 eval dataset sample:\")\n",
    "display(Slex_sorted.head())\n",
    "Slex_sorted = Slex_sorted.filter(items=['word1', 'word2', 'SimLex999', 'SD(SimLex)'], axis=1)\n",
    "Slex_sorted = Slex_sorted.sort_values(by=['SimLex999'], ascending=False)\n",
    "Slex_sorted = Slex_sorted.set_index(pd.Index(range(0,Slex_sorted.shape[0])))\n",
    "\n",
    "# Wsim_sorted = evalsetWsim.copy()\n",
    "# print(\"\\nWordSim-353 eval dataset sample:\")\n",
    "# display(Wsim_sorted.head())\n",
    "# Wsim_sorted = Wsim_sorted.sort_index(by=['Human (mean)'], ascending=False)\n",
    "# Wsim_sorted = Wsim_sorted.set_index(pd.Index(range(0,Wsim_sorted.shape[0])))\n",
    "# \n",
    "# Mens_sorted = evalsetMens.copy()\n",
    "# print(\"\\nMEN (3000) eval dataset sample:\")\n",
    "# display(Mens_sorted.head())\n",
    "# Mens_sorted = Mens_sorted.sort_index(by=['MEN_score'], ascending=False)\n",
    "# Mens_sorted = Mens_sorted.set_index(pd.Index(range(0,Mens_sorted.shape[0])))\n",
    "\n",
    "# add the rank column\n",
    "print('*'*80)\n",
    "rank = 0\n",
    "Slex_sorted['rank_simlex'] = Slex_sorted.index + 1\n",
    "print(\"\\nTop and bottom rows of ranked SimLex eval dataset:\")\n",
    "display(pd.concat([Slex_sorted.head(), Slex_sorted.tail()], axis=0))\n",
    "\n",
    "# rank = 0\n",
    "# Wsim_sorted['rank_wordsim'] = Wsim_sorted.index + 1\n",
    "# print(\"\\nTop and bottom rows of ranked WordSim eval dataset:\")\n",
    "# display(pd.concat([Wsim_sorted.head(), Wsim_sorted.tail()], axis=0))\n",
    "# \n",
    "# rank = 0\n",
    "# Mens_sorted['rank_men'] = Mens_sorted.index + 1\n",
    "# print(\"\\nTop and bottom rows of ranked MEN eval dataset:\")\n",
    "# display(pd.concat([Mens_sorted.head(), Mens_sorted.tail()], axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "      <th>rank_simlex</th>\n",
       "      <th>ngram_score</th>\n",
       "      <th>rank_ngram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vanish</td>\n",
       "      <td>disappear</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quick</td>\n",
       "      <td>rapid</td>\n",
       "      <td>9.70</td>\n",
       "      <td>1.14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.999613</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>creator</td>\n",
       "      <td>maker</td>\n",
       "      <td>9.62</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3</td>\n",
       "      <td>0.999376</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stupid</td>\n",
       "      <td>dumb</td>\n",
       "      <td>9.58</td>\n",
       "      <td>1.48</td>\n",
       "      <td>4</td>\n",
       "      <td>0.998607</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insane</td>\n",
       "      <td>crazy</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.92</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>large</td>\n",
       "      <td>big</td>\n",
       "      <td>9.55</td>\n",
       "      <td>0.44</td>\n",
       "      <td>6</td>\n",
       "      <td>0.998949</td>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>happy</td>\n",
       "      <td>cheerful</td>\n",
       "      <td>9.55</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7</td>\n",
       "      <td>0.997829</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cow</td>\n",
       "      <td>cattle</td>\n",
       "      <td>9.52</td>\n",
       "      <td>0.79</td>\n",
       "      <td>8</td>\n",
       "      <td>0.996512</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>area</td>\n",
       "      <td>region</td>\n",
       "      <td>9.47</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9</td>\n",
       "      <td>0.995170</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>large</td>\n",
       "      <td>huge</td>\n",
       "      <td>9.47</td>\n",
       "      <td>1.27</td>\n",
       "      <td>10</td>\n",
       "      <td>0.998236</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word1      word2  SimLex999  SD(SimLex)  rank_simlex  ngram_score  \\\n",
       "0   vanish  disappear       9.80        0.46            1     1.000000   \n",
       "1    quick      rapid       9.70        1.14            2     0.999613   \n",
       "2  creator      maker       9.62        1.40            3     0.999376   \n",
       "3   stupid       dumb       9.58        1.48            4     0.998607   \n",
       "4   insane      crazy       9.57        0.92            5     1.000000   \n",
       "5    large        big       9.55        0.44            6     0.998949   \n",
       "6    happy   cheerful       9.55        2.18            7     0.997829   \n",
       "7      cow     cattle       9.52        0.79            8     0.996512   \n",
       "8     area     region       9.47        0.58            9     0.995170   \n",
       "9    large       huge       9.47        1.27           10     0.998236   \n",
       "\n",
       "   rank_ngram  \n",
       "0           1  \n",
       "1         280  \n",
       "2         370  \n",
       "3         557  \n",
       "4          26  \n",
       "5         677  \n",
       "6         477  \n",
       "7         791  \n",
       "8         615  \n",
       "9         865  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'list' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-502-c9ea299b0baf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# elmo_Mens['rank_elmo'] = elmo_argsort + 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mngram_spearman\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mngram_spearman\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspearmanr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mngram_Slex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rank_simlex'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mngram_Slex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rank_ngram'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# elmo_spearman.append(scipy.stats.spearmanr(elmo_Wsim['rank_wordsim'], elmo_Wsim['rank_elmo'])[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'list' object is not callable"
     ]
    }
   ],
   "source": [
    "# Evaluating model's scoring on eval dataset(s)\n",
    "\n",
    "# Simlex\n",
    "ngram_Slex = Slex_sorted.copy()\n",
    "ngram_Slex['ngram_score'] = Slex_sorted.apply(lambda row: distances[(row['word1'], row['word2'])], axis=1 )\n",
    "ngram_Slex_sorted = ngram_Slex.sort_values(by=['ngram_score'], ascending=False)\n",
    "ngram_Slex_sorted = ngram_Slex_sorted.set_index(pd.Index(range(0,ngram_Slex_sorted.shape[0])))\n",
    "ngram_Slex_sorted['rank_ngram'] = ngram_Slex_sorted.index + 1\n",
    "ngram_Slex_sorted = ngram_Slex_sorted.sort_values(by=['SimLex999'], ascending=False)\n",
    "ngram_Slex['rank_ngram'] = ngram_Slex_sorted['rank_ngram'].values\n",
    "display(ngram_Slex[:10])\n",
    "\n",
    "# # Wordsim\n",
    "# elmo_Wsim = Wsim_sorted.copy()\n",
    "# elmo_Wsim['elmo_score'] = Wsim_sorted.apply(lambda row: elmo.similarity(row['Word 1'], row['Word 2']), axis=1 )\n",
    "# elmo_argsort = (-elmo_Wsim['elmo_score']).argsort()   # to sort in descending order\n",
    "# elmo_Wsim['rank_elmo'] = elmo_argsort + 1\n",
    "# \n",
    "# # MEN\n",
    "# elmo_Mens = Mens_sorted.copy()\n",
    "# elmo_Mens['elmo_score'] = Mens_sorted.apply(lambda row: elmo.similarity(row['word1'], row['word2']), axis=1 )\n",
    "# elmo_argsort = (-elmo_Mens['elmo_score']).argsort()   # to sort in descending order\n",
    "# elmo_Mens['rank_elmo'] = elmo_argsort + 1\n",
    "\n",
    "ngram_spearman = list()\n",
    "ngram_spearman.append(scipy.stats.spearmanr(ngram_Slex['rank_simlex'], ngram_Slex['rank_ngram'])[0])\n",
    "# elmo_spearman.append(scipy.stats.spearmanr(elmo_Wsim['rank_wordsim'], elmo_Wsim['rank_elmo'])[0])\n",
    "# elmo_spearman.append(scipy.stats.spearmanr(elmo_Mens['rank_men'], elmo_Mens['rank_elmo'])[0])\n",
    "\n",
    "print('*'*70)\n",
    "ngram_spearman_df = pd.DataFrame({'Dataset': evalset_name_list, 'Spearman rank coeff.': ngram_spearman})\n",
    "display(ngram_spearman_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.09598560484332026, pvalue=0.002389218824769293)"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.spearmanr(ngram_Slex['rank_simlex'], ngram_Slex['rank_ngram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "      <th>rank_simlex</th>\n",
       "      <th>ngram_score</th>\n",
       "      <th>rank_ngram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>container</td>\n",
       "      <td>mouse</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.95</td>\n",
       "      <td>990</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>ankle</td>\n",
       "      <td>window</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.80</td>\n",
       "      <td>991</td>\n",
       "      <td>0.998273</td>\n",
       "      <td>866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>cliff</td>\n",
       "      <td>tail</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.57</td>\n",
       "      <td>992</td>\n",
       "      <td>0.998870</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>hole</td>\n",
       "      <td>agreement</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.72</td>\n",
       "      <td>993</td>\n",
       "      <td>0.995155</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>island</td>\n",
       "      <td>task</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.96</td>\n",
       "      <td>994</td>\n",
       "      <td>0.997518</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>gun</td>\n",
       "      <td>fur</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.80</td>\n",
       "      <td>995</td>\n",
       "      <td>0.999802</td>\n",
       "      <td>174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>chapter</td>\n",
       "      <td>tail</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.57</td>\n",
       "      <td>996</td>\n",
       "      <td>0.999876</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>dirty</td>\n",
       "      <td>narrow</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.89</td>\n",
       "      <td>997</td>\n",
       "      <td>0.999251</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>new</td>\n",
       "      <td>ancient</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.46</td>\n",
       "      <td>998</td>\n",
       "      <td>0.996425</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>shrink</td>\n",
       "      <td>grow</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.20</td>\n",
       "      <td>999</td>\n",
       "      <td>0.999412</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word1      word2  SimLex999  SD(SimLex)  rank_simlex  ngram_score  \\\n",
       "989  container      mouse       0.30        0.95          990     0.999988   \n",
       "990      ankle     window       0.30        1.80          991     0.998273   \n",
       "991      cliff       tail       0.30        1.57          992     0.998870   \n",
       "992       hole  agreement       0.30        1.72          993     0.995155   \n",
       "993     island       task       0.30        0.96          994     0.997518   \n",
       "994        gun        fur       0.30        1.80          995     0.999802   \n",
       "995    chapter       tail       0.30        1.57          996     0.999876   \n",
       "996      dirty     narrow       0.30        0.89          997     0.999251   \n",
       "997        new    ancient       0.23        0.46          998     0.996425   \n",
       "998     shrink       grow       0.23        1.20          999     0.999412   \n",
       "\n",
       "     rank_ngram  \n",
       "989         574  \n",
       "990         866  \n",
       "991         210  \n",
       "992         608  \n",
       "993         403  \n",
       "994         174  \n",
       "995          63  \n",
       "996         500  \n",
       "997         359  \n",
       "998         803  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ngram_Slex[-10:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_candidates(corpus_tokenized, list_target_words, context, k):\n",
    "    counts = defaultdict(lambda: defaultdict(lambda: 0.0))\n",
    "    context_totals = dict()\n",
    "    w_1, w_2 = None, None\n",
    "    wordset = set()\n",
    "    for word in corpus_tokenized:\n",
    "        wordset.add(word)\n",
    "        if w_1 is not None and w_2 is not None:\n",
    "            counts[(w_2,w_1)][word] += 1\n",
    "            # Update context\n",
    "        w_2 = w_1\n",
    "        w_1 = word\n",
    "    for key, value in counts.items():\n",
    "        context_totals[key] = sum(value.values())\n",
    "    \n",
    "    words = list(wordset)\n",
    "    V = len(words)\n",
    "    \n",
    "    values=[]\n",
    "    \n",
    "    for word_x in list_target_words:\n",
    "    \n",
    "        C_abc = 0.0\n",
    "        if counts.get(context, 0.0) == 0.0:\n",
    "            C_abc = 0.0\n",
    "        else:\n",
    "            C_abc = counts.get(context, 0.0).get(word_x, 0.0)\n",
    "\n",
    "        C_ab = context_totals.get(context, 0.0)\n",
    "\n",
    "        values.append((word_x,(C_abc +k)/(C_ab +(k*V)) )) \n",
    "    return values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
