{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim                     # implements word2vec model infrastructure and provides interfacing APIs \n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import os\n",
    "from scipy import spatial\n",
    "from collections import defaultdict\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "import datetime\n",
    "import timeit \n",
    "\n",
    "# NLTK for NLP utils and corpora\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load pre-trained word2vec model\n",
    "word2vec_vectors = '../pretrained/GoogleNews-vectors-negative300.bin'\n",
    "w2v = gensim.models.KeyedVectors.load_word2vec_format(word2vec_vectors, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisWord = 'delay'\n",
    "thisSentence = 'i want this work finished without delay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar 20 words (by word) for 'delay' by word2vec model:\n",
      "['delayed', 'delays', 'delaying', 'postponement', 'postpone', 'postponing', 'Delays', 'Delaying', 'postponment', 'postponed', 'Delayed', 'stalling', 'Postponing', 'lateness', 'postponements', 'defer', 'inordinate_delay', 'indefinite_postponement', 'Lengthy_delays', 'glitch']\n"
     ]
    }
   ],
   "source": [
    "# most similar words - by word\n",
    "n_similar = 20\n",
    "synonyms = w2v.similar_by_word(thisWord, n_similar)\n",
    "\n",
    "synonyn_candidate = []\n",
    "for words in synonyms:\n",
    "    synonyn_candidate.append(words[0])\n",
    "\n",
    "print(\"Most similar {} words (by word) for '{}' by word2vec model:\".format(n_similar, thisWord))\n",
    "print(synonyn_candidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i want this work finished without delay\n",
      "delay  :  NN\n"
     ]
    }
   ],
   "source": [
    "sentence_pos_tag = nltk.pos_tag(thisSentence.split(' '))\n",
    "word_loc = 0\n",
    "word_pos = ''\n",
    "for word_idx, word in enumerate(sentence_pos_tag):\n",
    "    if(word[0] == thisWord):\n",
    "        word_loc = word_idx\n",
    "        word_pos = word[1]\n",
    "\n",
    "print (thisSentence)\n",
    "print (thisWord,' : ', word_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i want this work finished without delay\n",
      "delayed  :  NNS\n",
      "delays  :  NNS\n",
      "delaying  :  VBG\n",
      "postponement  :  NN\n",
      "postpone  :  NN\n",
      "postponing  :  VBG\n",
      "Delays  :  NNS\n",
      "Delaying  :  VBG\n",
      "postponment  :  NN\n",
      "postponed  :  VBN\n",
      "Delayed  :  NNP\n",
      "stalling  :  VBG\n",
      "Postponing  :  VBG\n",
      "lateness  :  NN\n",
      "postponements  :  NNS\n",
      "defer  :  NN\n",
      "inordinate_delay  :  NN\n",
      "indefinite_postponement  :  NN\n",
      "Lengthy_delays  :  NNS\n",
      "glitch  :  NN\n",
      "\n",
      "Filtered by POS (count :  8 ) ['postponement', 'postpone', 'postponment', 'lateness', 'defer', 'inordinate_delay', 'indefinite_postponement', 'glitch']\n"
     ]
    }
   ],
   "source": [
    "synonyn_candidate_filtered = []\n",
    "\n",
    "print (thisSentence)\n",
    "for candidate in synonyn_candidate:\n",
    "    newSentence = thisSentence.replace(thisWord, candidate)\n",
    "    sentence_pos_tag = nltk.pos_tag(newSentence.split(' '))\n",
    "    print(sentence_pos_tag[word_loc][0], ' : ', sentence_pos_tag[word_loc][1])\n",
    "    if sentence_pos_tag[word_loc][1] == word_pos:\n",
    "        synonyn_candidate_filtered.append(sentence_pos_tag[word_loc][0])\n",
    "\n",
    "print('\\nFiltered by POS (count : ',len(synonyn_candidate_filtered),')',synonyn_candidate_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.7310336   0.6544951   0.88699144 ...  0.00710861  0.25345138\n",
      "   0.56790507]]\n",
      "postponement\n",
      "postpone\n",
      "postponment\n",
      "lateness\n",
      "defer\n",
      "inordinate_delay\n",
      "indefinite_postponement\n",
      "glitch\n",
      "[(('delay', 'postponement'), 0.7414836193508368), (('delay', 'postpone'), 0.7060910486134683), (('delay', 'postponment'), 0.6268072842975166), (('delay', 'lateness'), 0.5315769360929473), (('delay', 'defer'), 0.6143004897106897), (('delay', 'inordinate_delay'), 0.43277463573228236), (('delay', 'indefinite_postponement'), 0.4909549409076789), (('delay', 'glitch'), 0.5327293626157836)]\n"
     ]
    }
   ],
   "source": [
    "sentence_split = thisSentence.split()\n",
    "embeddings = elmo(sentence_split, signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "main_embed = sess.run(embeddings)\n",
    "print(main_embed[word_loc])\n",
    "\n",
    "distances = []\n",
    "for idx, word in enumerate(synonyn_candidate_filtered):\n",
    "    sentence_temp = thisSentence.replace(thisWord, word)\n",
    "    sentence_split = sentence_temp.split()\n",
    "    embeddings = elmo(sentence_split, signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "    \n",
    "    init = tf.initialize_all_variables()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    embed = sess.run(embeddings)\n",
    "    \n",
    "    distance = 1 - spatial.distance.cosine(main_embed[word_loc], embed[word_loc])\n",
    "    distances.append(((thisWord, word), distance))\n",
    "    \n",
    "    print(word)\n",
    "    \n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i want this work finished without delay\n",
      "postponement :  0.741\n",
      "postpone :  0.706\n",
      "postponment :  0.627\n",
      "defer :  0.614\n",
      "glitch :  0.533\n",
      "lateness :  0.532\n",
      "indefinite_postponement :  0.491\n",
      "inordinate_delay :  0.433\n"
     ]
    }
   ],
   "source": [
    "distances_sorted = sorted(distances, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print (thisSentence)\n",
    "for dist in distances_sorted:\n",
    "    print (dist[0][1], ': ', round(dist[1],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
