{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeylee/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'rnnlm_test' from '/Users/jeylee/MIDS/W266/final/rnnlm_test.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import json, os, re, shutil, sys, time\n",
    "from importlib import reload\n",
    "import collections, itertools\n",
    "import unittest\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# NLTK for NLP utils and corpora\n",
    "import nltk\n",
    "\n",
    "# NumPy and TensorFlow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.startswith(\"1.\"))\n",
    "\n",
    "# Helper libraries\n",
    "from w266_common import utils, vocabulary, tf_embed_viz\n",
    "\n",
    "# Your code\n",
    "import rnnlm; reload(rnnlm)\n",
    "import rnnlm_test; reload(rnnlm_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_shapes_embed (rnnlm_test.TestRNNLMCore) ... ok\n",
      "test_shapes_output (rnnlm_test.TestRNNLMCore) ... ok\n",
      "test_shapes_recurrent (rnnlm_test.TestRNNLMCore) ... ok\n",
      "test_shapes_train (rnnlm_test.TestRNNLMTrain) ... ok\n",
      "test_shapes_sample (rnnlm_test.TestRNNLMSampler) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 2.273s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "reload(rnnlm)\n",
    "\n",
    "TF_GRAPHDIR = \"/Users/jeylee/mids/W266/tmp/w266/a3_graph\"\n",
    "\n",
    "# Clear old log directory.\n",
    "shutil.rmtree(TF_GRAPHDIR, ignore_errors=True)\n",
    "\n",
    "lm = rnnlm.RNNLM(V=10000, H=200, num_layers=2)\n",
    "lm.BuildCoreGraph()\n",
    "lm.BuildTrainGraph()\n",
    "lm.BuildSamplerGraph()\n",
    "\n",
    "summary_writer = tf.summary.FileWriter(TF_GRAPHDIR, lm.graph)\n",
    "\n",
    "reload(rnnlm); reload(rnnlm_test)\n",
    "utils.run_tests(rnnlm_test, [\"TestRNNLMCore\", \"TestRNNLMTrain\", \"TestRNNLMSampler\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above will load your implementation, construct the graph, and write a logdir for TensorBoard. You can bring up TensorBoard with:\n",
    "```\n",
    "cd assignment/a3\n",
    "tensorboard --logdir /tmp/w266/a3_graph --port 6006\n",
    "```\n",
    "Tensorboard : http://localhost:6006/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_epoch(lm, session, batch_iterator,\n",
    "              train=False, verbose=False,\n",
    "              tick_s=10, learning_rate=None):\n",
    "    assert(learning_rate is not None)\n",
    "    start_time = time.time()\n",
    "    tick_time = start_time  # for showing status\n",
    "    total_cost = 0.0  # total cost, summed over all words\n",
    "    total_batches = 0\n",
    "    total_words = 0\n",
    "\n",
    "    if train:\n",
    "        train_op = lm.train_step_\n",
    "        use_dropout = True\n",
    "        loss = lm.train_loss_\n",
    "    else:\n",
    "        train_op = tf.no_op()\n",
    "        use_dropout = False  # no dropout at test time\n",
    "        loss = lm.loss_  # true loss, if train_loss is an approximation\n",
    "\n",
    "    for i, (w, y) in enumerate(batch_iterator):\n",
    "        # At first batch in epoch, get a clean intitial state.\n",
    "        if i == 0:\n",
    "            h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "\n",
    "        feed_dict = {\n",
    "            lm.input_w_: w,\n",
    "            lm.target_y_: y,\n",
    "            lm.initial_h_: h,\n",
    "            lm.learning_rate_: learning_rate,\n",
    "            lm.use_dropout_: use_dropout\n",
    "        }\n",
    "        ops = [loss, lm.final_h_, train_op]        \n",
    "        #### YOUR CODE HERE ####\n",
    "        # session.run(...) the ops with the feed_dict constructed above.\n",
    "        # Ensure \"cost\" becomes the value of \"loss\".\n",
    "        # Hint: see \"ops\" for other variables that need updating in this loop.\n",
    "        \n",
    "        cost, h, _ = session.run([loss, lm.final_h_ ,train_op], feed_dict=feed_dict)\n",
    "        \n",
    "        #### END(YOUR CODE) ####\n",
    "        total_cost += cost\n",
    "        total_batches = i + 1\n",
    "        total_words += w.size  # w.size = batch_size * max_time\n",
    "\n",
    "        ##\n",
    "        # Print average loss-so-far for epoch\n",
    "        # If using train_loss_, this may be an underestimate.\n",
    "        if verbose and (time.time() - tick_time >= tick_s):\n",
    "            avg_cost = total_cost / total_batches\n",
    "            avg_wps = total_words / (time.time() - start_time)\n",
    "            print(\"[batch {:d}]: seen {:d} words at {:.1f} wps, loss = {:.3f}\".format(\n",
    "                i, total_words, avg_wps, avg_cost))\n",
    "            tick_time = time.time()  # reset time ticker\n",
    "\n",
    "    return total_cost / total_batches\n",
    "\n",
    "def score_dataset(lm, session, ids, name=\"Data\"):\n",
    "    # For scoring, we can use larger batches to speed things up.\n",
    "    bi = utils.rnnlm_batch_generator(ids, batch_size=100, max_time=100)\n",
    "    cost = run_epoch(lm, session, bi, \n",
    "                     learning_rate=0.0, train=False, \n",
    "                     verbose=False, tick_s=3600)\n",
    "    print(\"{:s}: avg. loss: {:.03f}  (perplexity: {:.02f})\".format(name, cost, np.exp(cost)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_toy_model (rnnlm_test.RunEpochTester) ... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch 149]: seen 7500 words at 7462.5 wps, loss = 0.698\n",
      "[batch 299]: seen 15000 words at 7469.5 wps, loss = 0.446\n",
      "[batch 455]: seen 22800 words at 7564.1 wps, loss = 0.336\n",
      "[batch 614]: seen 30750 words at 7658.6 wps, loss = 0.275\n",
      "[batch 776]: seen 38850 words at 7740.5 wps, loss = 0.234\n",
      "[batch 926]: seen 46350 words at 7699.8 wps, loss = 0.207\n",
      "[batch 1070]: seen 53550 words at 7627.1 wps, loss = 0.188\n",
      "[batch 1219]: seen 61000 words at 7599.4 wps, loss = 0.172\n",
      "[batch 1379]: seen 69000 words at 7643.4 wps, loss = 0.160\n",
      "[batch 1538]: seen 76950 words at 7671.7 wps, loss = 0.149\n",
      "[batch 1695]: seen 84800 words at 7684.6 wps, loss = 0.140\n",
      "[batch 1833]: seen 91700 words at 7618.9 wps, loss = 0.134\n",
      "[batch 1974]: seen 98750 words at 7572.8 wps, loss = 0.128\n",
      "[batch 2135]: seen 106800 words at 7606.4 wps, loss = 0.122\n",
      "[batch 2271]: seen 113600 words at 7548.9 wps, loss = 0.118\n",
      "[batch 2373]: seen 118700 words at 7391.2 wps, loss = 0.115\n",
      "[batch 2506]: seen 125350 words at 7346.5 wps, loss = 0.111\n",
      "[batch 2632]: seen 131650 words at 7284.7 wps, loss = 0.108\n",
      "[batch 2779]: seen 139000 words at 7286.4 wps, loss = 0.105\n",
      "[batch 2922]: seen 146150 words at 7279.5 wps, loss = 0.102\n",
      "[batch 3079]: seen 154000 words at 7302.8 wps, loss = 0.099\n",
      "[batch 3213]: seen 160700 words at 7275.1 wps, loss = 0.097\n",
      "[batch 3349]: seen 167500 words at 7252.7 wps, loss = 0.095\n",
      "[batch 3500]: seen 175050 words at 7262.8 wps, loss = 0.093\n",
      "[batch 3647]: seen 182400 words at 7265.1 wps, loss = 0.091\n",
      "[batch 3797]: seen 189900 words at 7272.1 wps, loss = 0.089\n",
      "[batch 3910]: seen 195550 words at 7211.7 wps, loss = 0.088\n",
      "Train set: avg. loss: 0.000  (perplexity: 1.00)\n",
      "Test set: avg. loss: 0.006  (perplexity: 1.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 29.945s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=1 errors=0 failures=0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(rnnlm); reload(rnnlm_test)\n",
    "th = rnnlm_test.RunEpochTester(\"test_toy_model\")\n",
    "th.setUp(); th.injectCode(run_epoch, score_dataset)\n",
    "unittest.TextTestRunner(verbosity=2).run(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /Users/jeylee/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "Vocabulary: 10,000 types\n",
      "Loaded 57,340 sentences (1.16119e+06 tokens)\n",
      "Training set: 45,872 sentences (924,077 tokens)\n",
      "Test set: 11,468 sentences (237,115 tokens)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "V = 10000\n",
    "vocab, train_ids, test_ids = utils.load_corpus(\"brown\", split=0.8, V=V, shuffle=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "max_time = 25\n",
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "\n",
    "# Model parameters\n",
    "model_params = dict(V=vocab.size, \n",
    "                    H=200, \n",
    "                    softmax_ns=200,\n",
    "                    num_layers=2)\n",
    "\n",
    "TF_SAVEDIR = \"/Users/jeylee/mids/W266/tmp/w266/a3_model\"\n",
    "checkpoint_filename = os.path.join(TF_SAVEDIR, \"rnnlm\")\n",
    "trained_filename = os.path.join(TF_SAVEDIR, \"rnnlm_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] Starting epoch 1\n",
      "[epoch 1] Completed in 0:01:53\n",
      "[epoch 1] Train set: avg. loss: 5.404  (perplexity: 222.30)\n",
      "[epoch 1] Test set: avg. loss: 5.440  (perplexity: 230.54)\n",
      "\n",
      "[epoch 2] Starting epoch 2\n",
      "[epoch 2] Completed in 0:01:40\n",
      "[epoch 2] Train set: avg. loss: 5.211  (perplexity: 183.23)\n",
      "[epoch 2] Test set: avg. loss: 5.265  (perplexity: 193.39)\n",
      "\n",
      "[epoch 3] Starting epoch 3\n",
      "[epoch 3] Completed in 0:02:01\n",
      "[epoch 3] Train set: avg. loss: 5.111  (perplexity: 165.90)\n",
      "[epoch 3] Test set: avg. loss: 5.177  (perplexity: 177.19)\n",
      "\n",
      "[epoch 4] Starting epoch 4\n",
      "[epoch 4] Completed in 0:01:44\n",
      "[epoch 4] Train set: avg. loss: 5.034  (perplexity: 153.55)\n",
      "[epoch 4] Test set: avg. loss: 5.113  (perplexity: 166.15)\n",
      "\n",
      "[epoch 5] Starting epoch 5\n",
      "[epoch 5] Completed in 0:01:30\n",
      "[epoch 5] Train set: avg. loss: 4.979  (perplexity: 145.30)\n",
      "[epoch 5] Test set: avg. loss: 5.070  (perplexity: 159.11)\n",
      "\n",
      "[epoch 6] Starting epoch 6\n",
      "[epoch 6] Completed in 0:01:30\n",
      "[epoch 6] Train set: avg. loss: 4.936  (perplexity: 139.17)\n",
      "[epoch 6] Test set: avg. loss: 5.037  (perplexity: 154.04)\n",
      "\n",
      "[epoch 7] Starting epoch 7\n",
      "[epoch 7] Completed in 0:07:17\n",
      "[epoch 7] Train set: avg. loss: 4.897  (perplexity: 133.95)\n",
      "[epoch 7] Test set: avg. loss: 5.011  (perplexity: 150.00)\n",
      "\n",
      "[epoch 8] Starting epoch 8\n",
      "[epoch 8] Completed in 0:01:29\n",
      "[epoch 8] Train set: avg. loss: 4.867  (perplexity: 129.98)\n",
      "[epoch 8] Test set: avg. loss: 4.988  (perplexity: 146.70)\n",
      "\n",
      "[epoch 9] Starting epoch 9\n",
      "[epoch 9] Completed in 0:01:30\n",
      "[epoch 9] Train set: avg. loss: 4.839  (perplexity: 126.33)\n",
      "[epoch 9] Test set: avg. loss: 4.969  (perplexity: 143.88)\n",
      "\n",
      "[epoch 10] Starting epoch 10\n",
      "[epoch 10] Completed in 0:01:47\n",
      "[epoch 10] Train set: avg. loss: 4.809  (perplexity: 122.56)\n",
      "[epoch 10] Test set: avg. loss: 4.954  (perplexity: 141.68)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Will print status every this many seconds\n",
    "print_interval = 5\n",
    "\n",
    "lm = rnnlm.RNNLM(**model_params)\n",
    "lm.BuildCoreGraph()\n",
    "lm.BuildTrainGraph()\n",
    "\n",
    "# Explicitly add global initializer and variable saver to LM graph\n",
    "with lm.graph.as_default():\n",
    "    initializer = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "# Clear old log directory\n",
    "shutil.rmtree(TF_SAVEDIR, ignore_errors=True)\n",
    "if not os.path.isdir(TF_SAVEDIR):\n",
    "    os.makedirs(TF_SAVEDIR)\n",
    "\n",
    "with tf.Session(graph=lm.graph) as session:\n",
    "    # Seed RNG for repeatability\n",
    "    tf.set_random_seed(42)\n",
    "\n",
    "    session.run(initializer)\n",
    "\n",
    "    for epoch in range(1,num_epochs+1):\n",
    "        t0_epoch = time.time()\n",
    "        bi = utils.rnnlm_batch_generator(train_ids, batch_size, max_time)\n",
    "        print(\"[epoch {:d}] Starting epoch {:d}\".format(epoch, epoch))\n",
    "        #### YOUR CODE HERE ####\n",
    "        # Run a training epoch.\n",
    "        \n",
    "        run_epoch(lm, session, bi, learning_rate=learning_rate, train=True, verbose=False, tick_s=10)\n",
    "        \n",
    "        #### END(YOUR CODE) ####\n",
    "        print(\"[epoch {:d}] Completed in {:s}\".format(epoch, utils.pretty_timedelta(since=t0_epoch)))\n",
    "    \n",
    "        # Save a checkpoint\n",
    "        saver.save(session, checkpoint_filename, global_step=epoch)\n",
    "    \n",
    "        ##\n",
    "        # score_dataset will run a forward pass over the entire dataset\n",
    "        # and report perplexity scores. This can be slow (around 1/2 to \n",
    "        # 1/4 as long as a full epoch), so you may want to comment it out\n",
    "        # to speed up training on a slow machine. Be sure to run it at the \n",
    "        # end to evaluate your score.\n",
    "        print(\"[epoch {:d}]\".format(epoch), end=\" \")\n",
    "        score_dataset(lm, session, train_ids, name=\"Train set\")\n",
    "        print(\"[epoch {:d}]\".format(epoch), end=\" \")\n",
    "        score_dataset(lm, session, test_ids, name=\"Test set\")\n",
    "        print(\"\")\n",
    "    \n",
    "    # Save final model\n",
    "    saver.save(session, trained_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Calculate Linguistic Probability\n",
    "\n",
    "Now that we've trained our RNNLM, let's test a few properties of the model to see how well it learns linguistic phenomena. We'll do this with a scoring task: given two or more test sentences, our model should score the more plausible (or more correct) sentence with a higher log-probability.\n",
    "\n",
    "We'll define a scoring function to help us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_seq(lm, session, seq, vocab):\n",
    "    \"\"\"Score a sequence of words. Returns total log-probability.\"\"\"\n",
    "    padded_ids = vocab.words_to_ids(utils.canonicalize_words([\"<s>\"] + seq + [\"</s>\"], \n",
    "                                                             wordset=vocab.word_to_id))\n",
    "    w = np.reshape(padded_ids[:-1], [1,-1])\n",
    "    y = np.reshape(padded_ids[1:],  [1,-1])\n",
    "    h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "    feed_dict = {lm.input_w_:w,\n",
    "                 lm.target_y_:y,\n",
    "                 lm.initial_h_:h,\n",
    "                 lm.dropout_keep_prob_: 1.0}\n",
    "    # Return log(P(seq)) = -1*loss\n",
    "    return -1*session.run(lm.loss_, feed_dict)\n",
    "\n",
    "def load_and_score(inputs, sort=False):\n",
    "    \"\"\"Load the trained model and score the given words.\"\"\"\n",
    "    lm = rnnlm.RNNLM(**model_params)\n",
    "    lm.BuildCoreGraph()\n",
    "    \n",
    "    with lm.graph.as_default():\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session(graph=lm.graph) as session:  \n",
    "        # Load the trained model\n",
    "        saver.restore(session, trained_filename)\n",
    "\n",
    "        if isinstance(inputs[0], str) or isinstance(inputs[0], bytes):\n",
    "            inputs = [inputs]\n",
    "\n",
    "        # Actually run scoring\n",
    "        results = []\n",
    "        for words in inputs:\n",
    "            score = score_seq(lm, session, words, vocab)\n",
    "            results.append((score, words))\n",
    "\n",
    "        # Sort if requested\n",
    "        if sort: results = sorted(results, reverse=True)\n",
    "\n",
    "        # Print results\n",
    "        for score, words in results:\n",
    "            print(\"\\\"{:s}\\\" : {:.02f}\".format(\" \".join(words), score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /Users/jeylee/mids/W266/tmp/w266/a3_model/rnnlm_trained\n",
      "\"We’re seeing unhealthy air quality throughout most of the Bay Area\" : -7.38\n",
      "\"We’re seeing unhealthy air quality all over most of the Bay Area\" : -7.25\n"
     ]
    }
   ],
   "source": [
    "sents = [\"We’re seeing unhealthy air quality throughout most of the Bay Area\",\n",
    "         \"We’re seeing unhealthy air quality all over most of the Bay Area\"]\n",
    "load_and_score([s.split() for s in sents])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
