{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantically related words using embeddings\n",
    "\n",
    "In this notebook, word embeddings using word2vec or GloVe on 1 Nillion corpus, is utilized to arrive at words with similar meanings.\n",
    "\n",
    "**Gensim word2vec APIs**: https://radimrehurek.com/gensim/models/word2vec.html\n",
    "\n",
    "**1 Billion corpus**: http://www.statmt.org/lm-benchmark/\n",
    "\n",
    "**Evaluation**\n",
    "\n",
    "The evaluation is done using SimLex-999 dataset. This is particularly challenging due to its differentiation between semantic similarity and semantic relatedness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim                     # implements word2vec model infrastructure and provides interfacing APIs \n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.test.utils import get_tmpfile, datapath\n",
    "from gensim.models.word2vec import *\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import codecs\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['word2vec']                                # list of models to eval: 'word2vec' \n",
    "                                                     # and 'glove' (trainng not implemented yet)\n",
    "\n",
    "path_corpus = '../datasets/1-billion-word-LM_corpus/1-billion-word-LM_corpus'\n",
    "path_corpus_proc = '../datasets/1-billion-word-LM_corpus/1-billion-word-LM_corpus_processed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approaches to train the word2vec model with, and the tradeoffs, as per *Mikolov*:\n",
    "\n",
    "**Skip-gram**: works well with small amount of the training data, represents well even rare words or phrases.  \n",
    "**CBOW**: several times faster to train than the skip-gram, slightly better accuracy for the frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for text decoding errors\n",
    "\n",
    "def decode_check(file_path):\n",
    "    dec_errors = 0\n",
    "    line_cnt = 0\n",
    "    with open(file_path, mode= 'r') as file:\n",
    "        try:\n",
    "            line = file.readline()\n",
    "        except:\n",
    "            dec_errors += 1\n",
    "        line_cnt += 1\n",
    "        while(line):\n",
    "            try:\n",
    "                line = file.readline()\n",
    "            except:\n",
    "                dec_errors += 1\n",
    "            line_cnt += 1\n",
    "    \n",
    "    print(\"{:20s}: {}\".format(\"\\nTotal line count\", line_cnt))\n",
    "    print(\"{:20s}: {}\".format(\"Line decoding errors\", dec_errors))\n",
    "    \n",
    "    return line_cnt, dec_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total line count   : 30726609\n",
      "Line decoding errors: 3247\n",
      "\n",
      "Pre-processing corpus...\n",
      "Dropped 3247 lines with decoding errors.\n",
      "Pre-processing done.\n",
      "\n",
      "Total line count   : 30723362\n",
      "Line decoding errors: 0\n"
     ]
    }
   ],
   "source": [
    "# inpsect and remove decoding errors from the corpus\n",
    "# the whole sentence needs to be removed, otherwise wrong context might be captured \n",
    "\n",
    "lineCnt, errorCnt = decode_check(path_corpus)\n",
    "\n",
    "if errorCnt != 0:\n",
    "    print('\\nPre-processing corpus...')\n",
    "    new_file = open(path_corpus_proc, 'w')\n",
    "    errorCnt = 0\n",
    "    \n",
    "    #with codecs.open(path_corpus, 'rb') as file:\n",
    "    #    try:\n",
    "    #        line = file.read().decode('utf-8', 'strict').encode('utf-8', 'strict')\n",
    "    #        new_file.write(line)\n",
    "    #    except:\n",
    "    #        line = None\n",
    "    #        errorCnt += 1\n",
    "    #    \n",
    "    #    while(line):\n",
    "    #        try:\n",
    "    #            line = file.read().decode('utf-8', 'strict').encode('utf-8', 'strict')\n",
    "    #            new_file.write(line)\n",
    "    #        except:\n",
    "    #            line = None\n",
    "    #            errorCnt += 1\n",
    "                \n",
    "    with open(path_corpus, mode='r') as file:\n",
    "        line = 1\n",
    "        while(line):\n",
    "            try:\n",
    "                line = file.readline()\n",
    "                print(line, file=new_file,end='')\n",
    "            except:\n",
    "                errorCnt += 1\n",
    "\n",
    "    new_file.close()\n",
    "    print(\"Dropped {} lines with decoding errors.\".format(errorCnt))\n",
    "    print('Pre-processing done.')\n",
    "\n",
    "    lineCnt, errorCnt = decode_check(path_corpus_proc)\n",
    "    assert errorCnt == 0\n",
    "    input_corpus = path_corpus_proc\n",
    "\n",
    "else:\n",
    "    input_corpus = path_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training word2vec model...\n",
      "Finished training.\n"
     ]
    }
   ],
   "source": [
    "# train models\n",
    "\n",
    "if 'word2vec' in models:\n",
    "    # initialize the model\n",
    "\n",
    "    input_sents = LineSentence(input_corpus)\n",
    "    print(\"Training word2vec model...\")\n",
    "    w2v = Word2Vec(input_sents, size=300, window=5, min_count=1, workers=16, sg=0)\n",
    "    print(\"Finished training.\")\n",
    "\n",
    "if 'glove' in models:\n",
    "    # load pre-trained GloVe model\n",
    "    glove_vectors = '../pretrained/glove.twitter.27B.200d.txt'\n",
    "    tmp_file = get_tmpfile(\"test_word2vec.txt\")\n",
    "    \n",
    "    glove2word2vec(glove_input_file=glove_vectors, word2vec_output_file=tmp_file)\n",
    "    glove = gensim.models.KeyedVectors.load_word2vec_format(tmp_file)\n",
    "    print(\"Loaded GloVe model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_embed = w2v.wv                # assigns embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec cosine similarity of ['coffee', 'cup']: 0.4199226200580597\n",
      "word2vec cosine similarity of ['coffee', 'tea']: 0.7134822607040405\n"
     ]
    }
   ],
   "source": [
    "# similarity \n",
    "pair1 = ['coffee','cup']\n",
    "pair2 = ['coffee','tea']\n",
    "\n",
    "if 'word2vec' in models:\n",
    "    cos_dist1_w = w2v_embed.similarity(pair1[0], pair1[1])\n",
    "    cos_dist2_w = w2v_embed.similarity(pair2[0], pair2[1])\n",
    "    print('word2vec cosine similarity of {}: {}'.format(pair1, cos_dist1_w) )\n",
    "    print('word2vec cosine similarity of {}: {}'.format(pair2, cos_dist2_w) )\n",
    "\n",
    "if 'glove' in models:\n",
    "    cos_dist1_g = glove.similarity(pair1[0], pair1[1])\n",
    "    cos_dist2_g = glove.similarity(pair2[0], pair2[1])\n",
    "    print('\\nGloVe cosine similarity of {}: {}'.format(pair1, cos_dist1_g) )\n",
    "    print('GloVe cosine similarity of {}: {}'.format(pair2, cos_dist2_g) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem above is that similarity doesn't always translate to synonyms - the target word 'minor' is closer to 'major' than to 'small'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word2vec Vector embedding dimension:  (300,)\n",
      "\n",
      "Printing a subset of the whole vector for the word 'coffee':\n",
      "[ 0.19272955 -0.7465307  -0.5118991  -0.13203195 -0.803349   -0.89371943\n",
      "  0.59276193 -0.71725786  1.1546805   0.4209137   0.594539   -1.625906\n",
      " -1.5279709  -0.95023376  0.6368995  -0.3045696  -0.1427788  -2.0711997\n",
      " -1.2850178 ]\n"
     ]
    }
   ],
   "source": [
    "# vector representation of the word\n",
    "\n",
    "if 'word2vec' in models:\n",
    "    vec_pair1_0_w = w2v_embed.get_vector(pair1[0])\n",
    "    print(\"word2vec Vector embedding dimension: \",vec_pair1_0_w.shape)\n",
    "    print(\"\\nPrinting a subset of the whole vector for the word '{}':\".format(pair1[0]))\n",
    "    print(vec_pair1_0_w[1:20])\n",
    "\n",
    "if 'glove' in models:\n",
    "    vec_pair1_0_g = glove.get_vector(pair1[0])\n",
    "    print(\"\\nGloVe vector embedding dimension: \",vec_pair1_0_g.shape)\n",
    "    print(\"\\nPrinting a subset of the whole vector for the word '{}':\".format(pair1[0]))\n",
    "    print(vec_pair1_0_g[1:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar 15 words (by word) for 'coffee' by word2vec model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cappuccino', 0.7345283031463623),\n",
       " ('coffees', 0.719455897808075),\n",
       " ('latte', 0.7135310173034668),\n",
       " ('tea', 0.7134822607040405),\n",
       " ('cappuccinos', 0.7123081684112549),\n",
       " ('lattes', 0.7047884464263916),\n",
       " ('beer', 0.6945380568504333),\n",
       " ('espresso', 0.691644549369812),\n",
       " ('snack', 0.6696176528930664),\n",
       " ('croissants', 0.6683788895606995),\n",
       " ('chai', 0.6663810014724731),\n",
       " ('chocolate', 0.6636378765106201),\n",
       " ('granola', 0.6541717052459717),\n",
       " ('gelato', 0.6520758867263794),\n",
       " ('mocha', 0.6493180990219116)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# most similar words - by word\n",
    "n_similar = 15\n",
    "thisWord = 'coffee'\n",
    "\n",
    "if 'word2vec' in models:\n",
    "    print(\"Most similar {} words (by word) for '{}' by word2vec model:\".format(n_similar, thisWord))\n",
    "    display(w2v.similar_by_word(thisWord, n_similar))\n",
    "\n",
    "if 'glove' in models:\n",
    "    print(\"\\nMost similar {} words (by word) for '{}' by GloVe model:\".format(n_similar, thisWord))\n",
    "    display(glove.similar_by_word(thisWord, n_similar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some odd words in the list of candidates as 'tea' and 'noodle', which ideally should be screened out, based on context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar 15 words (by vector) for 'coffee' by word2vec model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('cappuccino', 0.7345283031463623),\n",
       " ('coffees', 0.719455897808075),\n",
       " ('latte', 0.7135310173034668),\n",
       " ('tea', 0.7134822607040405),\n",
       " ('cappuccinos', 0.7123081684112549),\n",
       " ('lattes', 0.7047884464263916),\n",
       " ('beer', 0.6945380568504333),\n",
       " ('espresso', 0.691644549369812),\n",
       " ('snack', 0.6696176528930664),\n",
       " ('croissants', 0.6683788895606995),\n",
       " ('chai', 0.6663810014724731),\n",
       " ('chocolate', 0.6636378765106201),\n",
       " ('granola', 0.6541717052459717),\n",
       " ('gelato', 0.6520758867263794),\n",
       " ('mocha', 0.6493180990219116)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# most similar words - by vector\n",
    "\n",
    "if 'word2vec' in models:\n",
    "    print(\"Most similar {} words (by vector) for '{}' by word2vec model:\".format(n_similar, thisWord))\n",
    "    display(w2v.similar_by_vector(thisWord, n_similar))\n",
    "\n",
    "if 'glove' in models:\n",
    "    print(\"\\nMost similar {} words (by vector) for '{}' by GloVe model:\".format(n_similar, thisWord))\n",
    "    display(glove.similar_by_vector(thisWord, n_similar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the candidates and their order is exactly the same as using the similarity() metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>POS</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>conc(w1)</th>\n",
       "      <th>conc(w2)</th>\n",
       "      <th>concQ</th>\n",
       "      <th>Assoc(USF)</th>\n",
       "      <th>SimAssoc333</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old</td>\n",
       "      <td>new</td>\n",
       "      <td>A</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smart</td>\n",
       "      <td>intelligent</td>\n",
       "      <td>A</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1</td>\n",
       "      <td>7.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>difficult</td>\n",
       "      <td>A</td>\n",
       "      <td>8.77</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2</td>\n",
       "      <td>5.94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>cheerful</td>\n",
       "      <td>A</td>\n",
       "      <td>9.55</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1</td>\n",
       "      <td>5.85</td>\n",
       "      <td>1</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>easy</td>\n",
       "      <td>A</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  Assoc(USF)  \\\n",
       "0    old          new   A       1.58      2.72      2.81      2        7.25   \n",
       "1  smart  intelligent   A       9.20      1.75      2.46      1        7.11   \n",
       "2   hard    difficult   A       8.77      3.76      2.21      2        5.94   \n",
       "3  happy     cheerful   A       9.55      2.56      2.34      1        5.85   \n",
       "4   hard         easy   A       0.95      3.76      2.07      2        5.82   \n",
       "\n",
       "   SimAssoc333  SD(SimLex)  \n",
       "0            1        0.41  \n",
       "1            1        0.67  \n",
       "2            1        1.19  \n",
       "3            1        2.18  \n",
       "4            1        0.93  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load evaluation datsets\n",
    "path_evalset1 = '..\\\\datasets\\\\SimLex-999\\\\SimLex-999.txt'\n",
    "evalset1 = pd.read_csv(path_evalset1, sep='\\t')\n",
    "evalset1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above structure for SimLex-999 as evaluation dataset1, we'll be using the word pairs (columns `word1` and `word2`) as well as the `SimLex999` column for score on scale 1-10. Additionally, the `SD(SimLex)` column for standard deviation indicative of agreement between the human annotators for the given word pair, could be used for further investigation and possible waiving, in case discrepancy of the output from the model(s) to be evaluated.\n",
    "\n",
    "**Spearman correlation**\n",
    "\n",
    "Taken from [scipy.stats.spearman()](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.spearmanr.html)\n",
    "\n",
    "The Spearman correlation is a nonparametric measure of the monotonicity of the relationship between two datasets. Unlike the Pearson correlation, the Spearman correlation does not assume that both datasets are normally distributed. Like other correlation coefficients, this one varies between -1 and +1 with 0 implying no correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>POS</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>conc(w1)</th>\n",
       "      <th>conc(w2)</th>\n",
       "      <th>concQ</th>\n",
       "      <th>Assoc(USF)</th>\n",
       "      <th>SimAssoc333</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old</td>\n",
       "      <td>new</td>\n",
       "      <td>A</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smart</td>\n",
       "      <td>intelligent</td>\n",
       "      <td>A</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1</td>\n",
       "      <td>7.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>difficult</td>\n",
       "      <td>A</td>\n",
       "      <td>8.77</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2</td>\n",
       "      <td>5.94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>cheerful</td>\n",
       "      <td>A</td>\n",
       "      <td>9.55</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1</td>\n",
       "      <td>5.85</td>\n",
       "      <td>1</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>easy</td>\n",
       "      <td>A</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  Assoc(USF)  \\\n",
       "0    old          new   A       1.58      2.72      2.81      2        7.25   \n",
       "1  smart  intelligent   A       9.20      1.75      2.46      1        7.11   \n",
       "2   hard    difficult   A       8.77      3.76      2.21      2        5.94   \n",
       "3  happy     cheerful   A       9.55      2.56      2.34      1        5.85   \n",
       "4   hard         easy   A       0.95      3.76      2.07      2        5.82   \n",
       "\n",
       "   SimAssoc333  SD(SimLex)  \n",
       "0            1        0.41  \n",
       "1            1        0.67  \n",
       "2            1        1.19  \n",
       "3            1        2.18  \n",
       "4            1        0.93  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top rows of ranked eval dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vanish</td>\n",
       "      <td>disappear</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quick</td>\n",
       "      <td>rapid</td>\n",
       "      <td>9.70</td>\n",
       "      <td>1.14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>creator</td>\n",
       "      <td>maker</td>\n",
       "      <td>9.62</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stupid</td>\n",
       "      <td>dumb</td>\n",
       "      <td>9.58</td>\n",
       "      <td>1.48</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insane</td>\n",
       "      <td>crazy</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.92</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word1      word2  SimLex999  SD(SimLex)  rank\n",
       "0   vanish  disappear       9.80        0.46     1\n",
       "1    quick      rapid       9.70        1.14     2\n",
       "2  creator      maker       9.62        1.40     3\n",
       "3   stupid       dumb       9.58        1.48     4\n",
       "4   insane      crazy       9.57        0.92     5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bottom rows of ranked eval dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>gun</td>\n",
       "      <td>fur</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.80</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>chapter</td>\n",
       "      <td>tail</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.57</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>dirty</td>\n",
       "      <td>narrow</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.89</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>new</td>\n",
       "      <td>ancient</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.46</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>shrink</td>\n",
       "      <td>grow</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.20</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word1    word2  SimLex999  SD(SimLex)  rank\n",
       "994      gun      fur       0.30        1.80   995\n",
       "995  chapter     tail       0.30        1.57   996\n",
       "996    dirty   narrow       0.30        0.89   997\n",
       "997      new  ancient       0.23        0.46   998\n",
       "998   shrink     grow       0.23        1.20   999"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ranking the SimLex-999 scores\n",
    "\n",
    "# sort the eval dataset\n",
    "evalset1_sorted = evalset1.copy()\n",
    "display(evalset1_sorted.head())\n",
    "evalset1_sorted = evalset1_sorted.filter(items=['word1', 'word2', 'SimLex999', 'SD(SimLex)'], axis=1)\n",
    "evalset1_sorted = evalset1_sorted.sort_index(by=['SimLex999'], ascending=False)\n",
    "evalset1_sorted = evalset1_sorted.set_index(pd.Index(range(0,evalset1_sorted.shape[0])))\n",
    "\n",
    "# add the rank column\n",
    "rank = 0\n",
    "evalset1_sorted['rank'] = evalset1_sorted.index + 1\n",
    "print(\"\\nTop rows of ranked eval dataset:\")\n",
    "display(evalset1_sorted.head())\n",
    "print(\"\\nBottom rows of ranked eval dataset:\")\n",
    "display(evalset1_sorted.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "      <th>rank</th>\n",
       "      <th>w2v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vanish</td>\n",
       "      <td>disappear</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "      <td>0.906844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quick</td>\n",
       "      <td>rapid</td>\n",
       "      <td>9.70</td>\n",
       "      <td>1.14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.424930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>creator</td>\n",
       "      <td>maker</td>\n",
       "      <td>9.62</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3</td>\n",
       "      <td>0.295135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stupid</td>\n",
       "      <td>dumb</td>\n",
       "      <td>9.58</td>\n",
       "      <td>1.48</td>\n",
       "      <td>4</td>\n",
       "      <td>0.803944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insane</td>\n",
       "      <td>crazy</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.92</td>\n",
       "      <td>5</td>\n",
       "      <td>0.614515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word1      word2  SimLex999  SD(SimLex)  rank       w2v\n",
       "0   vanish  disappear       9.80        0.46     1  0.906844\n",
       "1    quick      rapid       9.70        1.14     2  0.424930\n",
       "2  creator      maker       9.62        1.40     3  0.295135\n",
       "3   stupid       dumb       9.58        1.48     4  0.803944\n",
       "4   insane      crazy       9.57        0.92     5  0.614515"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for word2vec model: 0.3683 \n"
     ]
    }
   ],
   "source": [
    "# Evaluating the models scoring on eval datasets\n",
    "\n",
    "w2v_scores = evalset1_sorted.copy()\n",
    "w2v_scores['w2v'] = evalset1_sorted.apply(lambda row: \n",
    "                                          w2v.similarity(row['word1'], row['word2']), axis=1 )\n",
    "display(w2v_scores.head())\n",
    "w2v_spearman = scipy.stats.spearmanr(w2v_scores['SimLex999'], w2v_scores['w2v'])\n",
    "print('Spearman correlation for word2vec model: {:6.4f} '.format(w2v_spearman[0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This maybe a coincidence, but **the value above for Spearman coefficient is very close with reporting on SimLex-999 page: **  \n",
    "https://fh295.github.io//simlex.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps:\n",
    "\n",
    "- Evaluate GloVe embedding model\n",
    "- Use other eval datasets as well - MENs and WordSim-353"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
