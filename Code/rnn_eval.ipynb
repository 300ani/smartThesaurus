{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import json, os, re, shutil, sys, time\n",
    "from importlib import reload\n",
    "import collections, itertools\n",
    "import unittest\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# NLTK for NLP utils and corpora\n",
    "import nltk\n",
    "\n",
    "# NumPy and TensorFlow\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "assert(tf.__version__.startswith(\"1.\"))\n",
    "\n",
    "# Helper libraries\n",
    "from rnn.w266_common import utils, vocabulary, tf_embed_viz\n",
    "\n",
    "import rnn.rnnlm as rnnlm;reload(rnnlm)\n",
    "import rnn.rnnlm_test as rnnlm_test;reload(rnnlm_test)\n",
    "from nltk.corpus import PlaintextCorpusReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_shapes_embed (rnn.rnnlm_test.TestRNNLMCore) ... ok\n",
      "test_shapes_output (rnn.rnnlm_test.TestRNNLMCore) ... ok\n",
      "test_shapes_recurrent (rnn.rnnlm_test.TestRNNLMCore) ... ok\n",
      "test_shapes_train (rnn.rnnlm_test.TestRNNLMTrain) ... ok\n",
      "test_shapes_sample (rnn.rnnlm_test.TestRNNLMSampler) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 2.232s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "reload(rnnlm)\n",
    "\n",
    "TF_GRAPHDIR = \"../pretrained/rnn_graph\"\n",
    "\n",
    "# Clear old log directory.\n",
    "shutil.rmtree(TF_GRAPHDIR, ignore_errors=True)\n",
    "\n",
    "lm = rnnlm.RNNLM(V=10000, H=200, num_layers=2)\n",
    "lm.BuildCoreGraph()\n",
    "lm.BuildTrainGraph()\n",
    "lm.BuildSamplerGraph()\n",
    "\n",
    "summary_writer = tf.summary.FileWriter(TF_GRAPHDIR, lm.graph)\n",
    "\n",
    "reload(rnnlm); reload(rnnlm_test)\n",
    "utils.run_tests(rnnlm_test, [\"TestRNNLMCore\", \"TestRNNLMTrain\", \"TestRNNLMSampler\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_epoch(lm, session, batch_iterator,\n",
    "              train=False, verbose=False,\n",
    "              tick_s=10, learning_rate=None):\n",
    "    assert(learning_rate is not None)\n",
    "    start_time = time.time()\n",
    "    tick_time = start_time  # for showing status\n",
    "    total_cost = 0.0  # total cost, summed over all words\n",
    "    total_batches = 0\n",
    "    total_words = 0\n",
    "\n",
    "    if train:\n",
    "        train_op = lm.train_step_\n",
    "        use_dropout = True\n",
    "        loss = lm.train_loss_\n",
    "    else:\n",
    "        train_op = tf.no_op()\n",
    "        use_dropout = False  # no dropout at test time\n",
    "        loss = lm.loss_  # true loss, if train_loss is an approximation\n",
    "\n",
    "    for i, (w, y) in enumerate(batch_iterator):\n",
    "        # At first batch in epoch, get a clean intitial state.\n",
    "        if i == 0:\n",
    "            h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "\n",
    "        feed_dict = {\n",
    "            lm.input_w_: w,\n",
    "            lm.target_y_: y,\n",
    "            lm.initial_h_: h,\n",
    "            lm.learning_rate_: learning_rate,\n",
    "            lm.use_dropout_: use_dropout\n",
    "        }\n",
    "        ops = [loss, lm.final_h_, train_op]        \n",
    "        #### YOUR CODE HERE ####\n",
    "        # session.run(...) the ops with the feed_dict constructed above.\n",
    "        # Ensure \"cost\" becomes the value of \"loss\".\n",
    "        # Hint: see \"ops\" for other variables that need updating in this loop.\n",
    "        \n",
    "        cost, h, _ = session.run([loss, lm.final_h_ ,train_op], feed_dict=feed_dict)\n",
    "        \n",
    "        #### END(YOUR CODE) ####\n",
    "        total_cost += cost\n",
    "        total_batches = i + 1\n",
    "        total_words += w.size  # w.size = batch_size * max_time\n",
    "\n",
    "        ##\n",
    "        # Print average loss-so-far for epoch\n",
    "        # If using train_loss_, this may be an underestimate.\n",
    "        if verbose and (time.time() - tick_time >= tick_s):\n",
    "            avg_cost = total_cost / total_batches\n",
    "            avg_wps = total_words / (time.time() - start_time)\n",
    "            print(\"[batch {:d}]: seen {:d} words at {:.1f} wps, loss = {:.3f}\".format(\n",
    "                i, total_words, avg_wps, avg_cost))\n",
    "            tick_time = time.time()  # reset time ticker\n",
    "\n",
    "    return total_cost / total_batches\n",
    "\n",
    "def score_dataset(lm, session, ids, name=\"Data\"):\n",
    "    # For scoring, we can use larger batches to speed things up.\n",
    "    bi = utils.rnnlm_batch_generator(ids, batch_size=100, max_time=100)\n",
    "    cost = run_epoch(lm, session, bi, \n",
    "                     learning_rate=0.0, train=False, \n",
    "                     verbose=False, tick_s=3600)\n",
    "    print(\"{:s}: avg. loss: {:.03f}  (perplexity: {:.02f})\".format(name, cost, np.exp(cost)))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['news.en-00001-of-00100']\n",
      "Vocabulary: 10,000 types\n",
      "Loaded 322,832 sentences (8.16567e+06 tokens)\n",
      "Training set: 258,265 sentences (6,532,540 tokens)\n",
      "Test set: 64,567 sentences (1,633,132 tokens)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "#V = 10000\n",
    "#vocab, train_ids, test_ids = utils.load_corpus(\"brown\", split=0.8, V=V, shuffle=42)\n",
    "corpus_root = '../datasets/training-monolingual.tokenized.shuffled'\n",
    "wordlists = PlaintextCorpusReader(corpus_root, 'news.en-00001.*')\n",
    "print(wordlists.fileids())\n",
    "wordlists.words()\n",
    "\n",
    "\n",
    "V = 10000\n",
    "vocab, train_ids, test_ids = utils.load_corpus(wordlists, split=0.8, V=V, shuffle=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "max_time = 25\n",
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "\n",
    "# Model parameters\n",
    "model_params = dict(V=vocab.size, \n",
    "                    H=200, \n",
    "                    softmax_ns=200,\n",
    "                    num_layers=2)\n",
    "\n",
    "TF_SAVEDIR = \"./rnn/rnn_model\"\n",
    "checkpoint_filename = os.path.join(TF_SAVEDIR, \"rnnlm\")\n",
    "trained_filename = os.path.join(TF_SAVEDIR, \"rnnlm_trained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch 1] Starting epoch 1\n",
      "[epoch 1] Completed in 0:13:43\n",
      "\n",
      "[epoch 2] Starting epoch 2\n",
      "[epoch 2] Completed in 0:15:41\n",
      "\n",
      "[epoch 3] Starting epoch 3\n",
      "[epoch 3] Completed in 0:12:47\n",
      "\n",
      "[epoch 4] Starting epoch 4\n",
      "[epoch 4] Completed in 0:11:57\n",
      "\n",
      "[epoch 5] Starting epoch 5\n",
      "[epoch 5] Completed in 0:11:37\n",
      "\n",
      "[epoch 6] Starting epoch 6\n",
      "[epoch 6] Completed in 0:11:17\n",
      "\n",
      "[epoch 7] Starting epoch 7\n",
      "[epoch 7] Completed in 0:10:56\n",
      "\n",
      "[epoch 8] Starting epoch 8\n",
      "[epoch 8] Completed in 0:10:59\n",
      "\n",
      "[epoch 9] Starting epoch 9\n",
      "[epoch 9] Completed in 0:12:15\n",
      "\n",
      "[epoch 10] Starting epoch 10\n",
      "[epoch 10] Completed in 0:12:21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Will print status every this many seconds\n",
    "print_interval = 5\n",
    "\n",
    "lm = rnnlm.RNNLM(**model_params)\n",
    "lm.BuildCoreGraph()\n",
    "lm.BuildTrainGraph()\n",
    "\n",
    "# Explicitly add global initializer and variable saver to LM graph\n",
    "with lm.graph.as_default():\n",
    "    initializer = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "# Clear old log directory\n",
    "shutil.rmtree(TF_SAVEDIR, ignore_errors=True)\n",
    "if not os.path.isdir(TF_SAVEDIR):\n",
    "    os.makedirs(TF_SAVEDIR)\n",
    "\n",
    "with tf.Session(graph=lm.graph) as session:\n",
    "    # Seed RNG for repeatability\n",
    "    tf.set_random_seed(42)\n",
    "\n",
    "    session.run(initializer)\n",
    "\n",
    "    for epoch in range(1,num_epochs+1):\n",
    "        t0_epoch = time.time()\n",
    "        bi = utils.rnnlm_batch_generator(train_ids, batch_size, max_time)\n",
    "        print(\"[epoch {:d}] Starting epoch {:d}\".format(epoch, epoch))\n",
    "        run_epoch(lm, session, bi, learning_rate=learning_rate, train=True, verbose=False, tick_s=10)\n",
    "        print(\"[epoch {:d}] Completed in {:s}\".format(epoch, utils.pretty_timedelta(since=t0_epoch)))\n",
    "    \n",
    "        # Save a checkpoint\n",
    "        saver.save(session, checkpoint_filename, global_step=epoch)\n",
    "    \n",
    "        ##\n",
    "        # score_dataset will run a forward pass over the entire dataset\n",
    "        # and report perplexity scores. This can be slow (around 1/2 to \n",
    "        # 1/4 as long as a full epoch), so you may want to comment it out\n",
    "        # to speed up training on a slow machine. Be sure to run it at the \n",
    "        # end to evaluate your score.\n",
    "        #print(\"[epoch {:d}]\".format(epoch), end=\" \")\n",
    "        #score_dataset(lm, session, train_ids, name=\"Train set\")\n",
    "        #print(\"[epoch {:d}]\".format(epoch), end=\" \")\n",
    "        #score_dataset(lm, session, test_ids, name=\"Test set\")\n",
    "        print(\"\")\n",
    "    \n",
    "    # Save final model\n",
    "    saver.save(session, trained_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_seq(lm, session, seq, vocab):\n",
    "    \"\"\"Score a sequence of words. Returns total log-probability.\"\"\"\n",
    "    padded_ids = vocab.words_to_ids(utils.canonicalize_words([\"<s>\"] + seq + [\"</s>\"], \n",
    "                                                             wordset=vocab.word_to_id))\n",
    "    w = np.reshape(padded_ids[:-1], [1,-1])\n",
    "    y = np.reshape(padded_ids[1:],  [1,-1])\n",
    "    h = session.run(lm.initial_h_, {lm.input_w_: w})\n",
    "    feed_dict = {lm.input_w_:w,\n",
    "                 lm.target_y_:y,\n",
    "                 lm.initial_h_:h,\n",
    "                 lm.dropout_keep_prob_: 1.0}\n",
    "    # Return log(P(seq)) = -1*loss\n",
    "    return -1*session.run(lm.loss_, feed_dict)\n",
    "\n",
    "def load_and_score(inputs, sort=True):\n",
    "    \"\"\"Load the trained model and score the given words.\"\"\"\n",
    "    lm = rnnlm.RNNLM(**model_params)\n",
    "    lm.BuildCoreGraph()\n",
    "    \n",
    "    with lm.graph.as_default():\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "    with tf.Session(graph=lm.graph) as session:  \n",
    "        # Load the trained model\n",
    "        saver.restore(session, trained_filename)\n",
    "\n",
    "        if isinstance(inputs[0], str) or isinstance(inputs[0], bytes):\n",
    "            inputs = [inputs]\n",
    "\n",
    "        # Actually run scoring\n",
    "        results = []\n",
    "        for words in inputs:\n",
    "            score = score_seq(lm, session, words, vocab)\n",
    "            sentence_gen = \" \".join(words)\n",
    "            results.append((score, sentence_gen))\n",
    "\n",
    "        # Sort if requested\n",
    "        if sort: results = sorted(results, reverse=True)\n",
    "            \n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./rnn/rnn_model/rnnlm_trained\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(-7.0964236259460449, 'the boy and the girl is'),\n",
       " (-7.1460084915161133, 'the boy and the girl are')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = [\"the boy and the girl is\",\n",
    "         \"the boy and the girl are\"]\n",
    "load_and_score([s.split() for s in sents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnn_eval :  9990  .......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "output_1 = open('./sentence_generator/output.txt', 'r').readlines()\n",
    "output_2 = open('./sentence_generator/output_2.txt', 'r').readlines()\n",
    "\n",
    "idx = 1\n",
    "per_word = 0\n",
    "\n",
    "sents_1 = []\n",
    "sents_2 = []\n",
    "avg_prob_1,avg_prob_2 = 0, 0\n",
    "final_result = []\n",
    "print(\"rnn_eval : \", len(output_1),' ', end=''),\n",
    "for i in range (0, len(output_1)):\n",
    "    split_1 = output_1[i].replace('\\n','').split(',')\n",
    "    split_2 = output_2[i].replace('\\n','').split(',')\n",
    "\n",
    "    sents_1.append(split_1[2])\n",
    "    sents_1.append(split_2[2].replace(split_2[1],split_1[1]))\n",
    "    sents_2.append(split_2[2])\n",
    "    sents_2.append(split_1[2].replace(split_1[1],split_2[1]))\n",
    "\n",
    "    if (i % 10) == 9:\n",
    "        print('.', end='')\n",
    "        score_1 = load_and_score([s.split() for s in sents_1])\n",
    "        score_2 = load_and_score([s.split() for s in sents_2])\n",
    "                \n",
    "        for score in score_1:\n",
    "            avg_prob_1 += score[0]\n",
    "        avg_prob_1 = avg_prob_1 / 20\n",
    "        \n",
    "        for score in score_2:\n",
    "            avg_prob_2 += score[0]\n",
    "        avg_prob_2 = avg_prob_2 / 20\n",
    "        \n",
    "        final_result.append([split_1[1], split_2[1], (avg_prob_1-avg_prob_2)])\n",
    "        \n",
    "        sents_1.clear()\n",
    "        sents_2.clear()\n",
    "        idx += 1\n",
    "        \n",
    "print('\\nFinished', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>POS</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>conc(w1)</th>\n",
       "      <th>conc(w2)</th>\n",
       "      <th>concQ</th>\n",
       "      <th>Assoc(USF)</th>\n",
       "      <th>SimAssoc333</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>old</td>\n",
       "      <td>new</td>\n",
       "      <td>A</td>\n",
       "      <td>1.58</td>\n",
       "      <td>2.72</td>\n",
       "      <td>2.81</td>\n",
       "      <td>2</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>smart</td>\n",
       "      <td>intelligent</td>\n",
       "      <td>A</td>\n",
       "      <td>9.20</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2.46</td>\n",
       "      <td>1</td>\n",
       "      <td>7.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hard</td>\n",
       "      <td>difficult</td>\n",
       "      <td>A</td>\n",
       "      <td>8.77</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.21</td>\n",
       "      <td>2</td>\n",
       "      <td>5.94</td>\n",
       "      <td>1</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>happy</td>\n",
       "      <td>cheerful</td>\n",
       "      <td>A</td>\n",
       "      <td>9.55</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.34</td>\n",
       "      <td>1</td>\n",
       "      <td>5.85</td>\n",
       "      <td>1</td>\n",
       "      <td>2.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hard</td>\n",
       "      <td>easy</td>\n",
       "      <td>A</td>\n",
       "      <td>0.95</td>\n",
       "      <td>3.76</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word1        word2 POS  SimLex999  conc(w1)  conc(w2)  concQ  Assoc(USF)  \\\n",
       "0    old          new   A       1.58      2.72      2.81      2        7.25   \n",
       "1  smart  intelligent   A       9.20      1.75      2.46      1        7.11   \n",
       "2   hard    difficult   A       8.77      3.76      2.21      2        5.94   \n",
       "3  happy     cheerful   A       9.55      2.56      2.34      1        5.85   \n",
       "4   hard         easy   A       0.95      3.76      2.07      2        5.82   \n",
       "\n",
       "   SimAssoc333  SD(SimLex)  \n",
       "0            1        0.41  \n",
       "1            1        0.67  \n",
       "2            1        1.19  \n",
       "3            1        2.18  \n",
       "4            1        0.93  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats\n",
    "\n",
    "# load evaluation datsets\n",
    "path_evalset1 = '../datasets/SimLex-999/SimLex-999.txt'\n",
    "evalset1 = pd.read_csv(path_evalset1, sep='\\t')\n",
    "evalset1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top and bottom rows of ranked SimLex eval dataset:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeylee/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: by argument to sort_index is deprecated, pls use .sort_values(by=...)\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "      <th>rank_simlex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vanish</td>\n",
       "      <td>disappear</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quick</td>\n",
       "      <td>rapid</td>\n",
       "      <td>9.70</td>\n",
       "      <td>1.14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>creator</td>\n",
       "      <td>maker</td>\n",
       "      <td>9.62</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stupid</td>\n",
       "      <td>dumb</td>\n",
       "      <td>9.58</td>\n",
       "      <td>1.48</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insane</td>\n",
       "      <td>crazy</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.92</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>gun</td>\n",
       "      <td>fur</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.80</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>chapter</td>\n",
       "      <td>tail</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.57</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>dirty</td>\n",
       "      <td>narrow</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.89</td>\n",
       "      <td>997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>new</td>\n",
       "      <td>ancient</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.46</td>\n",
       "      <td>998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>shrink</td>\n",
       "      <td>grow</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.20</td>\n",
       "      <td>999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word1      word2  SimLex999  SD(SimLex)  rank_simlex\n",
       "0     vanish  disappear       9.80        0.46            1\n",
       "1      quick      rapid       9.70        1.14            2\n",
       "2    creator      maker       9.62        1.40            3\n",
       "3     stupid       dumb       9.58        1.48            4\n",
       "4     insane      crazy       9.57        0.92            5\n",
       "994      gun        fur       0.30        1.80          995\n",
       "995  chapter       tail       0.30        1.57          996\n",
       "996    dirty     narrow       0.30        0.89          997\n",
       "997      new    ancient       0.23        0.46          998\n",
       "998   shrink       grow       0.23        1.20          999"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the models scoring on eval datasets\n",
    "\n",
    "models_score = evalset1.filter(items=['word1', 'word2', 'SimLex999', 'SD(SimLex)'])\n",
    "models_score = models_score.sort_index(by=['SimLex999'], ascending=False)\n",
    "models_score = models_score.set_index(pd.Index(range(0,models_score.shape[0])))\n",
    "\n",
    "models_score.head()\n",
    "\n",
    "# add the rank column\n",
    "rank = 0\n",
    "models_score['rank_simlex'] = models_score.index + 1\n",
    "print(\"\\nTop and bottom rows of ranked SimLex eval dataset:\")\n",
    "pd.concat([models_score.head(), models_score.tail()], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82890466123126139"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prob_diff(word_1, word_2):\n",
    "    pos_word_1 = [i for i,x in enumerate(final_result) if x[0] == word_1] # => [1, 3]\n",
    "    for idx in pos_word_1:\n",
    "        if final_result[idx][1] == word_2:\n",
    "            return abs(final_result[idx][2])\n",
    "    return -1\n",
    "\n",
    "prob_diff('vanish','disappear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "      <th>rank_simlex</th>\n",
       "      <th>rnn_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vanish</td>\n",
       "      <td>disappear</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "      <td>0.828905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quick</td>\n",
       "      <td>rapid</td>\n",
       "      <td>9.70</td>\n",
       "      <td>1.14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.012370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>creator</td>\n",
       "      <td>maker</td>\n",
       "      <td>9.62</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3</td>\n",
       "      <td>0.104025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stupid</td>\n",
       "      <td>dumb</td>\n",
       "      <td>9.58</td>\n",
       "      <td>1.48</td>\n",
       "      <td>4</td>\n",
       "      <td>0.761379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insane</td>\n",
       "      <td>crazy</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.92</td>\n",
       "      <td>5</td>\n",
       "      <td>0.845486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word1      word2  SimLex999  SD(SimLex)  rank_simlex  rnn_score\n",
       "0   vanish  disappear       9.80        0.46            1   0.828905\n",
       "1    quick      rapid       9.70        1.14            2   0.012370\n",
       "2  creator      maker       9.62        1.40            3   0.104025\n",
       "3   stupid       dumb       9.58        1.48            4   0.761379\n",
       "4   insane      crazy       9.57        0.92            5   0.845486"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_score['rnn_score'] = models_score.apply(lambda row: prob_diff(row['word1'],row['word2']), axis =1)\n",
    "models_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>SimLex999</th>\n",
       "      <th>SD(SimLex)</th>\n",
       "      <th>rank_simlex</th>\n",
       "      <th>rnn_score</th>\n",
       "      <th>rank_rnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vanish</td>\n",
       "      <td>disappear</td>\n",
       "      <td>9.80</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "      <td>0.828905</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quick</td>\n",
       "      <td>rapid</td>\n",
       "      <td>9.70</td>\n",
       "      <td>1.14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.012370</td>\n",
       "      <td>175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>creator</td>\n",
       "      <td>maker</td>\n",
       "      <td>9.62</td>\n",
       "      <td>1.40</td>\n",
       "      <td>3</td>\n",
       "      <td>0.104025</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stupid</td>\n",
       "      <td>dumb</td>\n",
       "      <td>9.58</td>\n",
       "      <td>1.48</td>\n",
       "      <td>4</td>\n",
       "      <td>0.761379</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>insane</td>\n",
       "      <td>crazy</td>\n",
       "      <td>9.57</td>\n",
       "      <td>0.92</td>\n",
       "      <td>5</td>\n",
       "      <td>0.845486</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>gun</td>\n",
       "      <td>fur</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.80</td>\n",
       "      <td>995</td>\n",
       "      <td>0.703535</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>chapter</td>\n",
       "      <td>tail</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.57</td>\n",
       "      <td>996</td>\n",
       "      <td>0.028255</td>\n",
       "      <td>599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>dirty</td>\n",
       "      <td>narrow</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.89</td>\n",
       "      <td>997</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>new</td>\n",
       "      <td>ancient</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.46</td>\n",
       "      <td>998</td>\n",
       "      <td>0.497806</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>shrink</td>\n",
       "      <td>grow</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.20</td>\n",
       "      <td>999</td>\n",
       "      <td>0.110749</td>\n",
       "      <td>383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word1      word2  SimLex999  SD(SimLex)  rank_simlex  rnn_score  \\\n",
       "0     vanish  disappear       9.80        0.46            1   0.828905   \n",
       "1      quick      rapid       9.70        1.14            2   0.012370   \n",
       "2    creator      maker       9.62        1.40            3   0.104025   \n",
       "3     stupid       dumb       9.58        1.48            4   0.761379   \n",
       "4     insane      crazy       9.57        0.92            5   0.845486   \n",
       "994      gun        fur       0.30        1.80          995   0.703535   \n",
       "995  chapter       tail       0.30        1.57          996   0.028255   \n",
       "996    dirty     narrow       0.30        0.89          997   0.061700   \n",
       "997      new    ancient       0.23        0.46          998   0.497806   \n",
       "998   shrink       grow       0.23        1.20          999   0.110749   \n",
       "\n",
       "     rank_rnn  \n",
       "0         116  \n",
       "1         175  \n",
       "2         202  \n",
       "3         113  \n",
       "4         564  \n",
       "994        89  \n",
       "995       599  \n",
       "996       195  \n",
       "997       255  \n",
       "998       383  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn_argsort = (-models_score['rnn_score']).argsort()   # to sort in descending order\n",
    "models_score['rank_rnn'] = rnn_argsort + 1\n",
    "pd.concat([models_score.head(), models_score.tail()], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman correlation for word2vec model: 0.0300 \n"
     ]
    }
   ],
   "source": [
    "rnn_spearman = scipy.stats.spearmanr(models_score['rank_simlex'], models_score['rank_rnn'])\n",
    "print('Spearman correlation for word2vec model: {:6.4f} '.format(rnn_spearman[0]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
