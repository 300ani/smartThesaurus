{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, re, json, time, unittest\n",
    "import itertools, collections\n",
    "from importlib import reload\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "import nltk\n",
    "\n",
    "# Helper libraries for this notebook\n",
    "from common import utils, vocabulary\n",
    "import ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /Users/nathanielschub/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "Loaded 54,716 sentences (1.72092e+06 tokens)\n",
      "Training set: 43,772 sentences (1,383,234 tokens)\n",
      "Test set: 10,944 sentences (337,683 tokens)\n",
      "Train set vocabulary: 26,822 words\n"
     ]
    }
   ],
   "source": [
    "assert(nltk.download('reuters'))  # Make sure we have the data.\n",
    "corpus = nltk.corpus.reuters\n",
    "V = 30000\n",
    "train_sents, test_sents = utils.get_train_test_sents(corpus, split=0.8, shuffle=False)\n",
    "# Build vocabulary only on the training set.\n",
    "vocab = vocabulary.Vocabulary((utils.canonicalize_word(w) for w in utils.flatten(train_sents)), size=V)\n",
    "print(\"Train set vocabulary: {:,} words\".format(vocab.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data: \n",
      " array(['<s>', '<s>', 'asian', 'exporters', 'fear', 'damage', 'from', 'u',\n",
      "       '.', 's', '.-', 'japan', 'rift', 'mounting', 'trade', 'friction',\n",
      "       'between', 'the', 'u', '.'], dtype=object)\n"
     ]
    }
   ],
   "source": [
    "def sents_to_tokens(sents):\n",
    "    \"\"\"Returns an flattened list of the words in the sentences, with padding for a trigram model.\"\"\"\n",
    "    padded_sentences = ([u\"<s>\", u\"<s>\"] + s + [u\"</s>\"] for s in sents)\n",
    "    # This will canonicalize words, and replace anything not in vocab with <unk>\n",
    "    return np.array([utils.canonicalize_word(w, wordset=vocab.wordset) \n",
    "                     for w in utils.flatten(padded_sentences)], dtype=object)\n",
    "\n",
    "train_tokens = sents_to_tokens(train_sents)\n",
    "test_tokens = sents_to_tokens(test_sents)\n",
    "print(\"Sample data: \\n\", repr(train_tokens[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building trigram LM... done in 2.44 s\n",
      "=== N-gram Language Model stats ===\n",
      "       0 unique 1-grams\n",
      "       0 unique 2-grams\n",
      " 640,922 unique 3-grams\n",
      "Optimal memory usage (counts only): 14.42 MB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reload(ngram)\n",
    "\n",
    "# Uncomment the line below for the model you want to run.\n",
    "Model = ngram.AddKTrigramLM\n",
    "#Model = ngram_lm.KNTrigramLM\n",
    "\n",
    "t0 = time.time()\n",
    "print(\"Building trigram LM... \", end=\"\")\n",
    "lm = Model(train_tokens)\n",
    "print(\"done in {:.02f} s\".format(time.time() - t0))\n",
    "lm.print_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8205fcfe01c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ms' is not defined"
     ]
    }
   ],
   "source": [
    "ms('test', ('test', 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
