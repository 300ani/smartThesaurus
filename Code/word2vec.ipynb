{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synonyms using pre-trained word2vec embeddings\n",
    "\n",
    "In this notebook, using word2vec pretrained embeddings on google news corpus is utilized to arrive at synsets (synomyms sets) that are words with similar meanings.\n",
    "\n",
    "**Gensim word2vec APIs**: https://radimrehurek.com/gensim/models/word2vec.html\n",
    "\n",
    "**Pre-trained word2vec model on google news**: https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing\n",
    "\n",
    "The above model is in the form of binary file that can be loaded into the environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim                     # implements word2vec model infrastructure and provides interfacing APIs \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained vectors\n",
    "w2v = gensim.models.KeyedVectors.load_word2vec_format('./pretrained/GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity of ['minor', 'small']: 0.3416362702846527\n",
      "Cosine similarity of ['minor', 'major']: 0.47539088129997253\n"
     ]
    }
   ],
   "source": [
    "# similarity \n",
    "pair1 = ['minor','small']\n",
    "pair2 = ['minor','major']\n",
    "cos_dist1 = w2v.similarity(pair1[0], pair1[1])\n",
    "cos_dist2 = w2v.similarity(pair2[0], pair2[1])\n",
    "\n",
    "print('Cosine similarity of {}: {}'.format(pair1, cos_dist1) )\n",
    "print('Cosine similarity of {}: {}'.format(pair2, cos_dist2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem above is that similarity doesn't always translate to synonyms - the target word 'minor' is closer to 'major' than to 'small'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector embedding dimension:  (300,)\n",
      "\n",
      "Printing a subset of the whole vector for the word 'minor':\n",
      "[ 0.06640625 -0.00228882  0.00402832 -0.28710938 -0.21972656  0.34765625\n",
      " -0.00494385 -0.01757812  0.12988281 -0.15917969 -0.15527344 -0.16992188\n",
      "  0.06933594 -0.14257812 -0.07958984  0.16992188  0.12109375  0.125\n",
      " -0.06494141]\n"
     ]
    }
   ],
   "source": [
    "# vector representation of the word\n",
    "vec_pair1_0 = w2v.get_vector(pair1[0])\n",
    "print(\"Vector embedding dimension: \",vec_pair1_0.shape)\n",
    "print(\"\\nPrinting a subset of the whole vector for the word '{}':\".format(pair1[0]))\n",
    "print(vec_pair1_0[1:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('biggest', 0.657293975353241),\n",
       " ('significant', 0.619140088558197),\n",
       " ('big', 0.6057686805725098),\n",
       " ('main', 0.5380213856697083),\n",
       " ('key', 0.5354758501052856),\n",
       " ('huge', 0.5329675674438477),\n",
       " ('signficant', 0.5157025456428528),\n",
       " ('amajor', 0.49914824962615967),\n",
       " ('largest', 0.49542921781539917),\n",
       " ('greatest', 0.49444860219955444)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most similar words - by word\n",
    "w2v.similar_by_word('major')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('minor', 1.0),\n",
       " ('serious', 0.5410230159759521),\n",
       " ('slight', 0.530189573764801),\n",
       " ('media_minHeight_=', 0.5136477947235107),\n",
       " ('Dr._Silvia_Priori', 0.5083508491516113),\n",
       " ('Minor', 0.5080995559692383),\n",
       " ('Soaked_hillsides_gave', 0.49214568734169006),\n",
       " ('minimal', 0.4815067946910858),\n",
       " ('WBO_lightweight_belts', 0.4774216115474701),\n",
       " ('major', 0.4753909111022949)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most similar words - by vector\n",
    "w2v.similar_by_vector(vec_pair1_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that similarity metric *by word* may offer better results than *by vector*. The above is just based on single sample, and needs further analysis with more samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps:\n",
    "- Try other forms of embeddings e.g. GloVe, fastText that can improve upon word2vec\n",
    "- Inspect the performace across less frequent words (fastText should perform better in this scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other resources\n",
    "- http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/\n",
    "- https://www.quora.com/Where-can-I-find-some-pre-trained-word-vectors-for-natural-language-processing-understanding\n",
    "- https://textminingonline.com/getting-started-with-word2vec-and-glove-in-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
